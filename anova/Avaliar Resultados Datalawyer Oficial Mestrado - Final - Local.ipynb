{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import pandas\n",
    "import researchpy as rp\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_results = Path('/media/discoD/models/elmo/ner/results_20_epochs_ibm')\n",
    "#path_results = Path('/media/discoD/models/elmo/ner/results_1_epoch_harem_all_combinations')\n",
    "# path_results = Path('/media/discoD/models/elmo/ner/mestrado/results_harem_final/')\n",
    "# path_results = Path('/media/discoD/models/elmo/ner/mestrado/results_datalawyer_final_3.1/')\n",
    "path_results = Path('/media/discoD/models/elmo/ner/mestrado/results_datalawyer_final_3.3/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/discoD/models/elmo/ner/mestrado/results_datalawyer_final_3.3/datalawyer-ft_ELMo+GloVe\n",
      "/media/discoD/models/elmo/ner/mestrado/results_datalawyer_final_3.3/datalawyer-ft_ELMo+Word2Vec-jur\n"
     ]
    }
   ],
   "source": [
    "for folder in path_results.iterdir():\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics.json not found for datalawyer-ft_ELMo+Word2Vec-jur_2\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "configs = dict()\n",
    "metrics = dict()\n",
    "for model_folder in path_results.iterdir():\n",
    "#     print('Reading embeddings folder from %s' % model_folder.name)\n",
    "    for embedding_folder in model_folder.iterdir():\n",
    "#         print('Reading files from %s' % embedding_folder.name)\n",
    "        key = embedding_folder.name\n",
    "#         print('Reading files from %s' % key)\n",
    "        has_metrics = False\n",
    "        for results_file in embedding_folder.iterdir():\n",
    "            if results_file.name.endswith('.json'):\n",
    "                #print('Parsing data from %s' % results_file.name)\n",
    "                if results_file.name.startswith('config'):\n",
    "                    configs[key] = json.loads(results_file.read_bytes())\n",
    "                elif results_file.name.startswith('metrics.'):\n",
    "                    metrics[key] = json.loads(results_file.read_bytes())\n",
    "                    has_metrics = True\n",
    "        if not has_metrics:\n",
    "            print('metrics.json not found for %s' % key)\n",
    "            del configs[key]\n",
    "    \n",
    "print(len(metrics))\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seconds(time_str):\n",
    "    x = time.strptime(time_str.split('.')[0],'%H:%M:%S')\n",
    "    return datetime.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
    "def get_average_epoch_duration(metrics):\n",
    "    seconds = get_seconds(metrics['training_duration'])\n",
    "    training_epochs = metrics['training_epochs'] + 1\n",
    "    return seconds / training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training_ID',\n",
       " 'Model',\n",
       " 'Representation',\n",
       " 'Embedding',\n",
       " 'Embedding_Type',\n",
       " 'Training_Number',\n",
       " 'Execution_Number',\n",
       " 'Best_Epoch',\n",
       " 'Training_Epochs',\n",
       " 'Training_Duration',\n",
       " 'Total_Duration(s)',\n",
       " 'Average_Epoch_Duration(s)',\n",
       " 'Training_Accuracy',\n",
       " 'Training_Accuracy_Top-3',\n",
       " 'Training_Precision',\n",
       " 'Training_Recall',\n",
       " 'Training_F1-Measure',\n",
       " 'Training_Loss',\n",
       " 'Best_Validation_Accuracy',\n",
       " 'Best_Validation_Accuracy_Top-3',\n",
       " 'Best_Validation_Precision',\n",
       " 'Best_Validation_Recall',\n",
       " 'Best_Validation_F1-Measure',\n",
       " 'Best_Validation_Loss',\n",
       " 'Test_Accuracy',\n",
       " 'Test_Accuracy_Top-3',\n",
       " 'Test_Precision',\n",
       " 'Test_Recall',\n",
       " 'Test_F1_Measure',\n",
       " 'Test_Loss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_ID = 'Training_ID'\n",
    "MODEL = 'Model'\n",
    "REPRESENTATION = 'Representation'\n",
    "EMBEDDING = 'Embedding'\n",
    "EMBEDDING_TYPE = 'Embedding_Type'\n",
    "BATCH_SIZE = 'Batch_Size'\n",
    "ELMO_DROPOUT = 'ELMo_Dropout'\n",
    "TRAINING_NUMBER = 'Training_Number'\n",
    "EXECUTION_NUMBER = 'Execution_Number'\n",
    "BEST_EPOCH = 'Best_Epoch'\n",
    "TRAINING_EPOCHS = 'Training_Epochs'\n",
    "TRAINING_DURATION = 'Training_Duration'\n",
    "TOTAL_DURATION = 'Total_Duration(s)'\n",
    "AVERAGE_EPOCH_DURATION = 'Average_Epoch_Duration(s)'\n",
    "TRAINING_ACCURACY = 'Training_Accuracy'\n",
    "TRAINING_ACCURACY_TOP3 = 'Training_Accuracy_Top-3'\n",
    "TRAINING_PRECISION = 'Training_Precision'\n",
    "TRAINING_RECALL = 'Training_Recall'\n",
    "TRAINING_F1_MEASURE = 'Training_F1-Measure'\n",
    "TRAINING_LOSS = 'Training_Loss'\n",
    "BEST_VALIDATION_ACCURACY = 'Best_Validation_Accuracy'\n",
    "BEST_VALIDATION_ACCURACY_TOP3 = 'Best_Validation_Accuracy_Top-3'\n",
    "BEST_VALIDATION_PRECISION = 'Best_Validation_Precision'\n",
    "BEST_VALIDATION_RECALL = 'Best_Validation_Recall'\n",
    "BEST_VALIDATION_F1_MEASURE = 'Best_Validation_F1-Measure'\n",
    "BEST_VALIDATION_LOSS = 'Best_Validation_Loss'\n",
    "TEST_ACCURACY = 'Test_Accuracy'\n",
    "TEST_ACCURACY_TOP3 = 'Test_Accuracy_Top-3'\n",
    "TEST_PRECISION = 'Test_Precision'\n",
    "TEST_RECALL = 'Test_Recall'\n",
    "TEST_F1_MEASURE = 'Test_F1_Measure'\n",
    "TEST_LOSS = 'Test_Loss'\n",
    "columns = [TRAINING_ID, MODEL, REPRESENTATION, EMBEDDING, EMBEDDING_TYPE, TRAINING_NUMBER, EXECUTION_NUMBER, BEST_EPOCH, TRAINING_EPOCHS, TRAINING_DURATION, TOTAL_DURATION, AVERAGE_EPOCH_DURATION, TRAINING_ACCURACY, TRAINING_ACCURACY_TOP3, TRAINING_PRECISION, TRAINING_RECALL, TRAINING_F1_MEASURE, TRAINING_LOSS, BEST_VALIDATION_ACCURACY, BEST_VALIDATION_ACCURACY_TOP3, BEST_VALIDATION_PRECISION, BEST_VALIDATION_RECALL, BEST_VALIDATION_F1_MEASURE, BEST_VALIDATION_LOSS, TEST_ACCURACY, TEST_ACCURACY_TOP3, TEST_PRECISION, TEST_RECALL, TEST_F1_MEASURE, TEST_LOSS]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_from_id(training_id, config):\n",
    "    data = training_id.split('_')\n",
    "    print(data)\n",
    "    if len(data) == 3:\n",
    "        return {MODEL: data[0], REPRESENTATION: data[1], EXECUTION_NUMBER: data[2]}\n",
    "    else:\n",
    "        print('Check id: %s' % training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datalawyer-ft', 'ELMo+GloVe', '0']\n",
      "['datalawyer-ft', 'ELMo+GloVe', '1']\n",
      "['datalawyer-ft', 'ELMo+Word2Vec-jur', '0']\n",
      "['datalawyer-ft', 'ELMo+Word2Vec-jur', '1']\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "for training_id, config in configs.items():\n",
    "    training_metrics = metrics[training_id]\n",
    "    data = get_training_data_from_id(training_id, config)\n",
    "    data[TRAINING_ID] = training_id\n",
    "    data[BEST_EPOCH] = training_metrics['best_epoch'] if training_metrics else None\n",
    "    data[TRAINING_EPOCHS] = training_metrics['training_epochs'] + 1 if training_metrics else None\n",
    "    data[TRAINING_DURATION] = training_metrics['training_duration'] if training_metrics else None\n",
    "    data[TOTAL_DURATION] = get_seconds(training_metrics['training_duration']) if training_metrics else None\n",
    "    data[AVERAGE_EPOCH_DURATION] = get_average_epoch_duration(training_metrics) if training_metrics else None\n",
    "    data[TRAINING_ACCURACY] = training_metrics['training_accuracy'] if training_metrics else None\n",
    "    data[TRAINING_ACCURACY_TOP3] = training_metrics['training_accuracy3'] if training_metrics else None\n",
    "    data[TRAINING_PRECISION] = training_metrics['training_precision-overall'] if training_metrics else None\n",
    "    data[TRAINING_RECALL] = training_metrics['training_recall-overall'] if training_metrics else None\n",
    "    data[TRAINING_F1_MEASURE] = training_metrics['training_f1-measure-overall'] if training_metrics else None\n",
    "    data[TRAINING_LOSS] = training_metrics['training_loss'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY] = training_metrics['best_validation_accuracy'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY_TOP3] = training_metrics['best_validation_accuracy3'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_PRECISION] = training_metrics['best_validation_precision-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_RECALL] = training_metrics['best_validation_recall-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_F1_MEASURE] = training_metrics['best_validation_f1-measure-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_LOSS] = training_metrics['best_validation_loss'] if training_metrics else None\n",
    "    data[TEST_ACCURACY] = training_metrics['test_accuracy'] if training_metrics else None\n",
    "    data[TEST_ACCURACY_TOP3] = training_metrics['test_accuracy3'] if training_metrics else None\n",
    "    data[TEST_PRECISION] = training_metrics['test_precision-overall'] if training_metrics else None\n",
    "    data[TEST_RECALL] = training_metrics['test_recall-overall'] if training_metrics else None\n",
    "    data[TEST_F1_MEASURE] = training_metrics['test_f1-measure-overall'] if training_metrics else None\n",
    "    data[TEST_LOSS] = training_metrics['test_loss'] if training_metrics else None\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Embedding_Type</th>\n",
       "      <th>Training_Number</th>\n",
       "      <th>Execution_Number</th>\n",
       "      <th>Best_Epoch</th>\n",
       "      <th>Training_Epochs</th>\n",
       "      <th>Training_Duration</th>\n",
       "      <th>Total_Duration(s)</th>\n",
       "      <th>Average_Epoch_Duration(s)</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Training_Accuracy_Top-3</th>\n",
       "      <th>Training_Precision</th>\n",
       "      <th>Training_Recall</th>\n",
       "      <th>Training_F1-Measure</th>\n",
       "      <th>Training_Loss</th>\n",
       "      <th>Best_Validation_Accuracy</th>\n",
       "      <th>Best_Validation_Accuracy_Top-3</th>\n",
       "      <th>Best_Validation_Precision</th>\n",
       "      <th>Best_Validation_Recall</th>\n",
       "      <th>Best_Validation_F1-Measure</th>\n",
       "      <th>Best_Validation_Loss</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Accuracy_Top-3</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1_Measure</th>\n",
       "      <th>Test_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datalawyer-ft_ELMo+GloVe_0</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+GloVe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>48</td>\n",
       "      <td>3:55:45.173863</td>\n",
       "      <td>14145.0</td>\n",
       "      <td>294.687500</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.989175</td>\n",
       "      <td>0.988720</td>\n",
       "      <td>0.988948</td>\n",
       "      <td>1.037505</td>\n",
       "      <td>0.992349</td>\n",
       "      <td>0.992575</td>\n",
       "      <td>0.936932</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.941684</td>\n",
       "      <td>17.482031</td>\n",
       "      <td>0.991801</td>\n",
       "      <td>0.991921</td>\n",
       "      <td>0.930888</td>\n",
       "      <td>0.928420</td>\n",
       "      <td>0.929652</td>\n",
       "      <td>19.878473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datalawyer-ft_ELMo+GloVe_1</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+GloVe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>4:06:22.970549</td>\n",
       "      <td>14782.0</td>\n",
       "      <td>295.640000</td>\n",
       "      <td>0.998908</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.988839</td>\n",
       "      <td>0.989180</td>\n",
       "      <td>0.989010</td>\n",
       "      <td>1.159503</td>\n",
       "      <td>0.992801</td>\n",
       "      <td>0.993055</td>\n",
       "      <td>0.939625</td>\n",
       "      <td>0.943935</td>\n",
       "      <td>0.941775</td>\n",
       "      <td>19.320777</td>\n",
       "      <td>0.993070</td>\n",
       "      <td>0.993444</td>\n",
       "      <td>0.937700</td>\n",
       "      <td>0.933722</td>\n",
       "      <td>0.935707</td>\n",
       "      <td>20.083548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datalawyer-ft_ELMo+Word2Vec-jur_0</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+Word2Vec-jur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>3:03:51.427517</td>\n",
       "      <td>11031.0</td>\n",
       "      <td>298.135135</td>\n",
       "      <td>0.998750</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>0.986766</td>\n",
       "      <td>0.986994</td>\n",
       "      <td>0.986880</td>\n",
       "      <td>1.351021</td>\n",
       "      <td>0.993380</td>\n",
       "      <td>0.993676</td>\n",
       "      <td>0.940283</td>\n",
       "      <td>0.946993</td>\n",
       "      <td>0.943626</td>\n",
       "      <td>14.378433</td>\n",
       "      <td>0.992174</td>\n",
       "      <td>0.992428</td>\n",
       "      <td>0.929104</td>\n",
       "      <td>0.924178</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>17.243205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datalawyer-ft_ELMo+Word2Vec-jur_1</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+Word2Vec-jur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>50</td>\n",
       "      <td>4:08:07.921361</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>297.740000</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.999057</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.991367</td>\n",
       "      <td>0.990683</td>\n",
       "      <td>1.129547</td>\n",
       "      <td>0.993027</td>\n",
       "      <td>0.993267</td>\n",
       "      <td>0.940041</td>\n",
       "      <td>0.942915</td>\n",
       "      <td>0.941476</td>\n",
       "      <td>16.747036</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>0.991831</td>\n",
       "      <td>0.933725</td>\n",
       "      <td>0.926299</td>\n",
       "      <td>0.929997</td>\n",
       "      <td>21.752093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Training_ID          Model     Representation  \\\n",
       "0         datalawyer-ft_ELMo+GloVe_0  datalawyer-ft         ELMo+GloVe   \n",
       "1         datalawyer-ft_ELMo+GloVe_1  datalawyer-ft         ELMo+GloVe   \n",
       "2  datalawyer-ft_ELMo+Word2Vec-jur_0  datalawyer-ft  ELMo+Word2Vec-jur   \n",
       "3  datalawyer-ft_ELMo+Word2Vec-jur_1  datalawyer-ft  ELMo+Word2Vec-jur   \n",
       "\n",
       "   Embedding  Embedding_Type  Training_Number Execution_Number  Best_Epoch  \\\n",
       "0        NaN             NaN              NaN                0          23   \n",
       "1        NaN             NaN              NaN                1          46   \n",
       "2        NaN             NaN              NaN                0          12   \n",
       "3        NaN             NaN              NaN                1          34   \n",
       "\n",
       "   Training_Epochs Training_Duration  Total_Duration(s)  \\\n",
       "0               48    3:55:45.173863            14145.0   \n",
       "1               50    4:06:22.970549            14782.0   \n",
       "2               37    3:03:51.427517            11031.0   \n",
       "3               50    4:08:07.921361            14887.0   \n",
       "\n",
       "   Average_Epoch_Duration(s)  Training_Accuracy  Training_Accuracy_Top-3  \\\n",
       "0                 294.687500           0.998929                 0.998969   \n",
       "1                 295.640000           0.998908                 0.998929   \n",
       "2                 298.135135           0.998750                 0.998793   \n",
       "3                 297.740000           0.999042                 0.999057   \n",
       "\n",
       "   Training_Precision  Training_Recall  Training_F1-Measure  Training_Loss  \\\n",
       "0            0.989175         0.988720             0.988948       1.037505   \n",
       "1            0.988839         0.989180             0.989010       1.159503   \n",
       "2            0.986766         0.986994             0.986880       1.351021   \n",
       "3            0.990000         0.991367             0.990683       1.129547   \n",
       "\n",
       "   Best_Validation_Accuracy  Best_Validation_Accuracy_Top-3  \\\n",
       "0                  0.992349                        0.992575   \n",
       "1                  0.992801                        0.993055   \n",
       "2                  0.993380                        0.993676   \n",
       "3                  0.993027                        0.993267   \n",
       "\n",
       "   Best_Validation_Precision  Best_Validation_Recall  \\\n",
       "0                   0.936932                0.946483   \n",
       "1                   0.939625                0.943935   \n",
       "2                   0.940283                0.946993   \n",
       "3                   0.940041                0.942915   \n",
       "\n",
       "   Best_Validation_F1-Measure  Best_Validation_Loss  Test_Accuracy  \\\n",
       "0                    0.941684             17.482031       0.991801   \n",
       "1                    0.941775             19.320777       0.993070   \n",
       "2                    0.943626             14.378433       0.992174   \n",
       "3                    0.941476             16.747036       0.991607   \n",
       "\n",
       "   Test_Accuracy_Top-3  Test_Precision  Test_Recall  Test_F1_Measure  \\\n",
       "0             0.991921        0.930888     0.928420         0.929652   \n",
       "1             0.993444        0.937700     0.933722         0.935707   \n",
       "2             0.992428        0.929104     0.924178         0.926635   \n",
       "3             0.991831        0.933725     0.926299         0.929997   \n",
       "\n",
       "   Test_Loss  \n",
       "0  19.878473  \n",
       "1  20.083548  \n",
       "2  17.243205  \n",
       "3  21.752093  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "training_data_df = pd.DataFrame(training_data, columns=columns)\n",
    "# training_data_df = training_data_df[(training_data_df[EXECUTION_NUMBER]).astype(int) == 0]\n",
    "training_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(training_data_df[(training_data_df[EXECUTION_NUMBER]).astype(int) == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.to_csv('training_data_50_epochs_datalawyer_final.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3:48:31.250000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.timedelta(seconds=training_data_df[TOTAL_DURATION].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_exported_columns = ['mean', 'min', 'max', 'std']\n",
    "renamed_columns = ['Contagem', 'F-Score', 'Desvio Padrão', 'Mínimo', '25%', '50%', '75%', 'Máximo']\n",
    "exported_columns_names = ['F-Score', 'Mínimo', 'Máximo', 'Desvio Padrão']\n",
    "model_map = {'harem-ft': 'Sim', 'harem': 'Não'}\n",
    "representation_map = {'ELMo+CNN+Embeddings': 'ELMo+CNN+Vetor', 'ELMo+Embeddings': 'ELMo+Vetor'}\n",
    "embedding_type_map = {'skip': 'Skip-Gram', 'No': 'Sem Vetor', 'cbow': 'CBoW'}\n",
    "embedding_map = {'wang2vec': 'Wang2Vec', 'glove': 'GloVe', 'word2vec': 'Word2Vec', 'No': 'Sem Vetor', 'fasttext': 'FastText'}\n",
    "replacements_map = {**model_map, **representation_map, **embedding_type_map, **embedding_map}\n",
    "\n",
    "def get_group_csv(index_names, group_name, group_columns, target_value, index_map, dataframe=training_data_df, exported_columns=default_exported_columns):\n",
    "    if type(index_names) == str:\n",
    "        index_names = [index_names]\n",
    "    group = dataframe.groupby(group_columns).describe()[target_value].sort_values(by='mean', ascending=False)\n",
    "    for column in exported_columns:\n",
    "        group[column] = group[column] * 100\n",
    "    group.index.names = index_names\n",
    "    group = group.rename(index=index_map)\n",
    "    group.columns = renamed_columns\n",
    "    group.to_csv('grupo_' + group_name + '_50_epochs_mestrado_datalawyer_final.csv', columns=exported_columns_names, float_format = '%.2f%%')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contagem</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Máximo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Representação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ELMo+GloVe</th>\n",
       "      <td>2.0</td>\n",
       "      <td>93.267947</td>\n",
       "      <td>0.428114</td>\n",
       "      <td>92.965224</td>\n",
       "      <td>0.931166</td>\n",
       "      <td>0.932679</td>\n",
       "      <td>0.934193</td>\n",
       "      <td>93.570670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELMo+Word2Vec-jur</th>\n",
       "      <td>2.0</td>\n",
       "      <td>92.831605</td>\n",
       "      <td>0.237770</td>\n",
       "      <td>92.663477</td>\n",
       "      <td>0.927475</td>\n",
       "      <td>0.928316</td>\n",
       "      <td>0.929157</td>\n",
       "      <td>92.999734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Contagem    F-Score  Desvio Padrão     Mínimo       25%  \\\n",
       "Representação                                                                \n",
       "ELMo+GloVe              2.0  93.267947       0.428114  92.965224  0.931166   \n",
       "ELMo+Word2Vec-jur       2.0  92.831605       0.237770  92.663477  0.927475   \n",
       "\n",
       "                        50%       75%     Máximo  \n",
       "Representação                                     \n",
       "ELMo+GloVe         0.932679  0.934193  93.570670  \n",
       "ELMo+Word2Vec-jur  0.928316  0.929157  92.999734  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_csv('Representação', REPRESENTATION, REPRESENTATION, TEST_F1_MEASURE, replacements_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = Path('/media/discoD/models/elmo/ner/mestrado/scores_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "scores_wang2vec_selective, scores_wang2vec_total, scores_glove_selective, scores_glove_total = [], [], [], []\n",
    "for score_file in scores_path.iterdir():\n",
    "    score = score_file.open(mode='r', encoding='utf8').readlines()[1].split()[-1]\n",
    "    if 'Wang2Vec' in score_file.name:\n",
    "        if 'selective' in score_file.name:\n",
    "            scores_wang2vec_selective.append(float(score))\n",
    "        elif 'total' in score_file.name:\n",
    "            scores_wang2vec_total.append(float(score))\n",
    "    elif 'GloVe' in score_file.name:\n",
    "        if 'selective' in score_file.name:\n",
    "            scores_glove_selective.append(float(score))\n",
    "        elif 'total' in score_file.name:\n",
    "            scores_glove_total.append(float(score))\n",
    "print(len(scores_wang2vec_selective))\n",
    "print(len(scores_wang2vec_total))\n",
    "print(len(scores_glove_selective))\n",
    "print(len(scores_glove_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83.222\n",
      "78.037\n",
      "82.886\n",
      "77.631\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(scores_wang2vec_selective))\n",
    "print(statistics.mean(scores_wang2vec_total))\n",
    "print(statistics.mean(scores_glove_selective))\n",
    "print(statistics.mean(scores_glove_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_datalawyer_path = Path('/media/discoD/models/elmo/ner/mestrado/scores_final_datalawyer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "scores_word2vec, scores_glove = [], []\n",
    "for score_file in scores_datalawyer_path.iterdir():\n",
    "    score = score_file.open(mode='r', encoding='utf8').readlines()[1].split()[-1]\n",
    "    if 'Word2Vec' in score_file.name:\n",
    "        scores_word2vec.append(float(score))\n",
    "    elif 'GloVe' in score_file.name:\n",
    "        scores_glove.append(float(score))\n",
    "print(len(scores_word2vec))\n",
    "print(len(scores_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.405\n",
      "93.81\n"
     ]
    }
   ],
   "source": [
    "print(statistics.mean(scores_word2vec))\n",
    "print(statistics.mean(scores_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38890872965260914\n",
      "0.3535533905932738\n"
     ]
    }
   ],
   "source": [
    "print(statistics.stdev(scores_word2vec))\n",
    "print(statistics.stdev(scores_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AllenNLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
