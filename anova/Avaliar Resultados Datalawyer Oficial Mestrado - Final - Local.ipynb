{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import pandas\n",
    "import researchpy as rp\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_results = Path('/media/discoD/models/elmo/ner/results_20_epochs_ibm')\n",
    "#path_results = Path('/media/discoD/models/elmo/ner/results_1_epoch_harem_all_combinations')\n",
    "# path_results = Path('/media/discoD/models/elmo/ner/mestrado/results_harem_final/')\n",
    "path_results = Path('/media/discoD/models/elmo/ner/elmo_jur/results_final/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/discoD/models/elmo/ner/elmo_jur/results_final/datalawyer-ft_ELMo+GloVe\n",
      "/media/discoD/models/elmo/ner/elmo_jur/results_final/datalawyer-ft_ELMo+Word2Vec-jur\n"
     ]
    }
   ],
   "source": [
    "for folder in path_results.iterdir():\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics.json not found for datalawyer-ft_ELMo+Word2Vec-jur_2\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "configs = dict()\n",
    "metrics = dict()\n",
    "for model_folder in path_results.iterdir():\n",
    "#     print('Reading embeddings folder from %s' % model_folder.name)\n",
    "    for embedding_folder in model_folder.iterdir():\n",
    "#         print('Reading files from %s' % embedding_folder.name)\n",
    "        key = embedding_folder.name\n",
    "#         print('Reading files from %s' % key)\n",
    "        has_metrics = False\n",
    "        for results_file in embedding_folder.iterdir():\n",
    "            if results_file.name.endswith('.json'):\n",
    "                #print('Parsing data from %s' % results_file.name)\n",
    "                if results_file.name.startswith('config'):\n",
    "                    configs[key] = json.loads(results_file.read_bytes())\n",
    "                elif results_file.name.startswith('metrics.'):\n",
    "                    metrics[key] = json.loads(results_file.read_bytes())\n",
    "                    has_metrics = True\n",
    "        if not has_metrics:\n",
    "            print('metrics.json not found for %s' % key)\n",
    "            del configs[key]\n",
    "    \n",
    "print(len(metrics))\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seconds(time_str):\n",
    "    x = time.strptime(time_str.split('.')[0],'%H:%M:%S')\n",
    "    return datetime.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
    "def get_average_epoch_duration(metrics):\n",
    "    seconds = get_seconds(metrics['training_duration'])\n",
    "    training_epochs = metrics['training_epochs'] + 1\n",
    "    return seconds / training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training_ID',\n",
       " 'Model',\n",
       " 'Representation',\n",
       " 'Embedding',\n",
       " 'Embedding_Type',\n",
       " 'Training_Number',\n",
       " 'Execution_Number',\n",
       " 'Best_Epoch',\n",
       " 'Training_Epochs',\n",
       " 'Training_Duration',\n",
       " 'Total_Duration(s)',\n",
       " 'Average_Epoch_Duration(s)',\n",
       " 'Training_Accuracy',\n",
       " 'Training_Accuracy_Top-3',\n",
       " 'Training_Precision',\n",
       " 'Training_Recall',\n",
       " 'Training_F1-Measure',\n",
       " 'Training_Loss',\n",
       " 'Best_Validation_Accuracy',\n",
       " 'Best_Validation_Accuracy_Top-3',\n",
       " 'Best_Validation_Precision',\n",
       " 'Best_Validation_Recall',\n",
       " 'Best_Validation_F1-Measure',\n",
       " 'Best_Validation_Loss',\n",
       " 'Test_Accuracy',\n",
       " 'Test_Accuracy_Top-3',\n",
       " 'Test_Precision',\n",
       " 'Test_Recall',\n",
       " 'Test_F1_Measure',\n",
       " 'Test_Loss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_ID = 'Training_ID'\n",
    "MODEL = 'Model'\n",
    "REPRESENTATION = 'Representation'\n",
    "EMBEDDING = 'Embedding'\n",
    "EMBEDDING_TYPE = 'Embedding_Type'\n",
    "BATCH_SIZE = 'Batch_Size'\n",
    "ELMO_DROPOUT = 'ELMo_Dropout'\n",
    "TRAINING_NUMBER = 'Training_Number'\n",
    "EXECUTION_NUMBER = 'Execution_Number'\n",
    "BEST_EPOCH = 'Best_Epoch'\n",
    "TRAINING_EPOCHS = 'Training_Epochs'\n",
    "TRAINING_DURATION = 'Training_Duration'\n",
    "TOTAL_DURATION = 'Total_Duration(s)'\n",
    "AVERAGE_EPOCH_DURATION = 'Average_Epoch_Duration(s)'\n",
    "TRAINING_ACCURACY = 'Training_Accuracy'\n",
    "TRAINING_ACCURACY_TOP3 = 'Training_Accuracy_Top-3'\n",
    "TRAINING_PRECISION = 'Training_Precision'\n",
    "TRAINING_RECALL = 'Training_Recall'\n",
    "TRAINING_F1_MEASURE = 'Training_F1-Measure'\n",
    "TRAINING_LOSS = 'Training_Loss'\n",
    "BEST_VALIDATION_ACCURACY = 'Best_Validation_Accuracy'\n",
    "BEST_VALIDATION_ACCURACY_TOP3 = 'Best_Validation_Accuracy_Top-3'\n",
    "BEST_VALIDATION_PRECISION = 'Best_Validation_Precision'\n",
    "BEST_VALIDATION_RECALL = 'Best_Validation_Recall'\n",
    "BEST_VALIDATION_F1_MEASURE = 'Best_Validation_F1-Measure'\n",
    "BEST_VALIDATION_LOSS = 'Best_Validation_Loss'\n",
    "TEST_ACCURACY = 'Test_Accuracy'\n",
    "TEST_ACCURACY_TOP3 = 'Test_Accuracy_Top-3'\n",
    "TEST_PRECISION = 'Test_Precision'\n",
    "TEST_RECALL = 'Test_Recall'\n",
    "TEST_F1_MEASURE = 'Test_F1_Measure'\n",
    "TEST_LOSS = 'Test_Loss'\n",
    "columns = [TRAINING_ID, MODEL, REPRESENTATION, EMBEDDING, EMBEDDING_TYPE, TRAINING_NUMBER, EXECUTION_NUMBER, BEST_EPOCH, TRAINING_EPOCHS, TRAINING_DURATION, TOTAL_DURATION, AVERAGE_EPOCH_DURATION, TRAINING_ACCURACY, TRAINING_ACCURACY_TOP3, TRAINING_PRECISION, TRAINING_RECALL, TRAINING_F1_MEASURE, TRAINING_LOSS, BEST_VALIDATION_ACCURACY, BEST_VALIDATION_ACCURACY_TOP3, BEST_VALIDATION_PRECISION, BEST_VALIDATION_RECALL, BEST_VALIDATION_F1_MEASURE, BEST_VALIDATION_LOSS, TEST_ACCURACY, TEST_ACCURACY_TOP3, TEST_PRECISION, TEST_RECALL, TEST_F1_MEASURE, TEST_LOSS]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_from_id(training_id, config):\n",
    "    data = training_id.split('_')\n",
    "    print(data)\n",
    "    if len(data) == 3:\n",
    "        return {MODEL: data[0], REPRESENTATION: data[1], EXECUTION_NUMBER: data[2]}\n",
    "    else:\n",
    "        print('Check id: %s' % training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datalawyer-ft', 'ELMo+GloVe', '1']\n",
      "['datalawyer-ft', 'ELMo+GloVe', '0']\n",
      "['datalawyer-ft', 'ELMo+Word2Vec-jur', '1']\n",
      "['datalawyer-ft', 'ELMo+Word2Vec-jur', '0']\n"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "for training_id, config in configs.items():\n",
    "    training_metrics = metrics[training_id]\n",
    "    data = get_training_data_from_id(training_id, config)\n",
    "    data[TRAINING_ID] = training_id\n",
    "    data[BEST_EPOCH] = training_metrics['best_epoch'] if training_metrics else None\n",
    "    data[TRAINING_EPOCHS] = training_metrics['training_epochs'] + 1 if training_metrics else None\n",
    "    data[TRAINING_DURATION] = training_metrics['training_duration'] if training_metrics else None\n",
    "    data[TOTAL_DURATION] = get_seconds(training_metrics['training_duration']) if training_metrics else None\n",
    "    data[AVERAGE_EPOCH_DURATION] = get_average_epoch_duration(training_metrics) if training_metrics else None\n",
    "    data[TRAINING_ACCURACY] = training_metrics['training_accuracy'] if training_metrics else None\n",
    "    data[TRAINING_ACCURACY_TOP3] = training_metrics['training_accuracy3'] if training_metrics else None\n",
    "    data[TRAINING_PRECISION] = training_metrics['training_precision-overall'] if training_metrics else None\n",
    "    data[TRAINING_RECALL] = training_metrics['training_recall-overall'] if training_metrics else None\n",
    "    data[TRAINING_F1_MEASURE] = training_metrics['training_f1-measure-overall'] if training_metrics else None\n",
    "    data[TRAINING_LOSS] = training_metrics['training_loss'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY] = training_metrics['best_validation_accuracy'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY_TOP3] = training_metrics['best_validation_accuracy3'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_PRECISION] = training_metrics['best_validation_precision-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_RECALL] = training_metrics['best_validation_recall-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_F1_MEASURE] = training_metrics['best_validation_f1-measure-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_LOSS] = training_metrics['best_validation_loss'] if training_metrics else None\n",
    "    data[TEST_ACCURACY] = training_metrics['test_accuracy'] if training_metrics else None\n",
    "    data[TEST_ACCURACY_TOP3] = training_metrics['test_accuracy3'] if training_metrics else None\n",
    "    data[TEST_PRECISION] = training_metrics['test_precision-overall'] if training_metrics else None\n",
    "    data[TEST_RECALL] = training_metrics['test_recall-overall'] if training_metrics else None\n",
    "    data[TEST_F1_MEASURE] = training_metrics['test_f1-measure-overall'] if training_metrics else None\n",
    "    data[TEST_LOSS] = training_metrics['test_loss'] if training_metrics else None\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training_ID</th>\n",
       "      <th>Model</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Embedding_Type</th>\n",
       "      <th>Training_Number</th>\n",
       "      <th>Execution_Number</th>\n",
       "      <th>Best_Epoch</th>\n",
       "      <th>Training_Epochs</th>\n",
       "      <th>Training_Duration</th>\n",
       "      <th>Total_Duration(s)</th>\n",
       "      <th>Average_Epoch_Duration(s)</th>\n",
       "      <th>Training_Accuracy</th>\n",
       "      <th>Training_Accuracy_Top-3</th>\n",
       "      <th>Training_Precision</th>\n",
       "      <th>Training_Recall</th>\n",
       "      <th>Training_F1-Measure</th>\n",
       "      <th>Training_Loss</th>\n",
       "      <th>Best_Validation_Accuracy</th>\n",
       "      <th>Best_Validation_Accuracy_Top-3</th>\n",
       "      <th>Best_Validation_Precision</th>\n",
       "      <th>Best_Validation_Recall</th>\n",
       "      <th>Best_Validation_F1-Measure</th>\n",
       "      <th>Best_Validation_Loss</th>\n",
       "      <th>Test_Accuracy</th>\n",
       "      <th>Test_Accuracy_Top-3</th>\n",
       "      <th>Test_Precision</th>\n",
       "      <th>Test_Recall</th>\n",
       "      <th>Test_F1_Measure</th>\n",
       "      <th>Test_Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>datalawyer-ft_ELMo+GloVe_1</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+GloVe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>50</td>\n",
       "      <td>3:34:51.681323</td>\n",
       "      <td>12891.0</td>\n",
       "      <td>257.820000</td>\n",
       "      <td>0.998762</td>\n",
       "      <td>0.998765</td>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.986883</td>\n",
       "      <td>0.987502</td>\n",
       "      <td>3.202651</td>\n",
       "      <td>0.989780</td>\n",
       "      <td>0.990055</td>\n",
       "      <td>0.918682</td>\n",
       "      <td>0.928720</td>\n",
       "      <td>0.923674</td>\n",
       "      <td>78.992337</td>\n",
       "      <td>0.989373</td>\n",
       "      <td>0.989736</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.918459</td>\n",
       "      <td>0.916854</td>\n",
       "      <td>75.037300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>datalawyer-ft_ELMo+GloVe_0</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+GloVe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>47</td>\n",
       "      <td>5:05:50.499079</td>\n",
       "      <td>18350.0</td>\n",
       "      <td>390.425532</td>\n",
       "      <td>0.998780</td>\n",
       "      <td>0.998813</td>\n",
       "      <td>0.986998</td>\n",
       "      <td>0.987111</td>\n",
       "      <td>0.987054</td>\n",
       "      <td>2.998385</td>\n",
       "      <td>0.989620</td>\n",
       "      <td>0.989896</td>\n",
       "      <td>0.918557</td>\n",
       "      <td>0.927159</td>\n",
       "      <td>0.922838</td>\n",
       "      <td>67.784462</td>\n",
       "      <td>0.989038</td>\n",
       "      <td>0.989178</td>\n",
       "      <td>0.914457</td>\n",
       "      <td>0.914457</td>\n",
       "      <td>0.914457</td>\n",
       "      <td>62.990981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>datalawyer-ft_ELMo+Word2Vec-jur_1</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+Word2Vec-jur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>4:14:48.670650</td>\n",
       "      <td>15288.0</td>\n",
       "      <td>305.760000</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>0.998737</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.985514</td>\n",
       "      <td>0.985851</td>\n",
       "      <td>3.054027</td>\n",
       "      <td>0.989925</td>\n",
       "      <td>0.990171</td>\n",
       "      <td>0.916070</td>\n",
       "      <td>0.931322</td>\n",
       "      <td>0.923633</td>\n",
       "      <td>75.780935</td>\n",
       "      <td>0.988076</td>\n",
       "      <td>0.988453</td>\n",
       "      <td>0.906746</td>\n",
       "      <td>0.914457</td>\n",
       "      <td>0.910585</td>\n",
       "      <td>76.731462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>datalawyer-ft_ELMo+Word2Vec-jur_0</td>\n",
       "      <td>datalawyer-ft</td>\n",
       "      <td>ELMo+Word2Vec-jur</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>3:03:13.440573</td>\n",
       "      <td>10993.0</td>\n",
       "      <td>314.085714</td>\n",
       "      <td>0.998431</td>\n",
       "      <td>0.998470</td>\n",
       "      <td>0.983349</td>\n",
       "      <td>0.983461</td>\n",
       "      <td>0.983405</td>\n",
       "      <td>4.172801</td>\n",
       "      <td>0.990084</td>\n",
       "      <td>0.990403</td>\n",
       "      <td>0.926653</td>\n",
       "      <td>0.933403</td>\n",
       "      <td>0.930016</td>\n",
       "      <td>55.163136</td>\n",
       "      <td>0.989498</td>\n",
       "      <td>0.989861</td>\n",
       "      <td>0.917335</td>\n",
       "      <td>0.915958</td>\n",
       "      <td>0.916646</td>\n",
       "      <td>53.653293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Training_ID          Model     Representation  \\\n",
       "0         datalawyer-ft_ELMo+GloVe_1  datalawyer-ft         ELMo+GloVe   \n",
       "1         datalawyer-ft_ELMo+GloVe_0  datalawyer-ft         ELMo+GloVe   \n",
       "2  datalawyer-ft_ELMo+Word2Vec-jur_1  datalawyer-ft  ELMo+Word2Vec-jur   \n",
       "3  datalawyer-ft_ELMo+Word2Vec-jur_0  datalawyer-ft  ELMo+Word2Vec-jur   \n",
       "\n",
       "   Embedding  Embedding_Type  Training_Number Execution_Number  Best_Epoch  \\\n",
       "0        NaN             NaN              NaN                1          40   \n",
       "1        NaN             NaN              NaN                0          22   \n",
       "2        NaN             NaN              NaN                1          35   \n",
       "3        NaN             NaN              NaN                0          10   \n",
       "\n",
       "   Training_Epochs Training_Duration  Total_Duration(s)  \\\n",
       "0               50    3:34:51.681323            12891.0   \n",
       "1               47    5:05:50.499079            18350.0   \n",
       "2               50    4:14:48.670650            15288.0   \n",
       "3               35    3:03:13.440573            10993.0   \n",
       "\n",
       "   Average_Epoch_Duration(s)  Training_Accuracy  Training_Accuracy_Top-3  \\\n",
       "0                 257.820000           0.998762                 0.998765   \n",
       "1                 390.425532           0.998780                 0.998813   \n",
       "2                 305.760000           0.998710                 0.998737   \n",
       "3                 314.085714           0.998431                 0.998470   \n",
       "\n",
       "   Training_Precision  Training_Recall  Training_F1-Measure  Training_Loss  \\\n",
       "0            0.988122         0.986883             0.987502       3.202651   \n",
       "1            0.986998         0.987111             0.987054       2.998385   \n",
       "2            0.986189         0.985514             0.985851       3.054027   \n",
       "3            0.983349         0.983461             0.983405       4.172801   \n",
       "\n",
       "   Best_Validation_Accuracy  Best_Validation_Accuracy_Top-3  \\\n",
       "0                  0.989780                        0.990055   \n",
       "1                  0.989620                        0.989896   \n",
       "2                  0.989925                        0.990171   \n",
       "3                  0.990084                        0.990403   \n",
       "\n",
       "   Best_Validation_Precision  Best_Validation_Recall  \\\n",
       "0                   0.918682                0.928720   \n",
       "1                   0.918557                0.927159   \n",
       "2                   0.916070                0.931322   \n",
       "3                   0.926653                0.933403   \n",
       "\n",
       "   Best_Validation_F1-Measure  Best_Validation_Loss  Test_Accuracy  \\\n",
       "0                    0.923674             78.992337       0.989373   \n",
       "1                    0.922838             67.784462       0.989038   \n",
       "2                    0.923633             75.780935       0.988076   \n",
       "3                    0.930016             55.163136       0.989498   \n",
       "\n",
       "   Test_Accuracy_Top-3  Test_Precision  Test_Recall  Test_F1_Measure  \\\n",
       "0             0.989736        0.915254     0.918459         0.916854   \n",
       "1             0.989178        0.914457     0.914457         0.914457   \n",
       "2             0.988453        0.906746     0.914457         0.910585   \n",
       "3             0.989861        0.917335     0.915958         0.916646   \n",
       "\n",
       "   Test_Loss  \n",
       "0  75.037300  \n",
       "1  62.990981  \n",
       "2  76.731462  \n",
       "3  53.653293  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "training_data_df = pd.DataFrame(training_data, columns=columns)\n",
    "# training_data_df = training_data_df[(training_data_df[EXECUTION_NUMBER]).astype(int) == 0]\n",
    "training_data_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(training_data_df[(training_data_df[EXECUTION_NUMBER]).astype(int) == i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.to_csv('training_data_50_epochs_datalawyer_final.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3:59:40.500000'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.timedelta(seconds=training_data_df[TOTAL_DURATION].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_exported_columns = ['mean', 'min', 'max', 'std']\n",
    "renamed_columns = ['Contagem', 'F-Score', 'Desvio Padrão', 'Mínimo', '25%', '50%', '75%', 'Máximo']\n",
    "exported_columns_names = ['F-Score', 'Mínimo', 'Máximo', 'Desvio Padrão']\n",
    "model_map = {'harem-ft': 'Sim', 'harem': 'Não'}\n",
    "representation_map = {'ELMo+CNN+Embeddings': 'ELMo+CNN+Vetor', 'ELMo+Embeddings': 'ELMo+Vetor'}\n",
    "embedding_type_map = {'skip': 'Skip-Gram', 'No': 'Sem Vetor', 'cbow': 'CBoW'}\n",
    "embedding_map = {'wang2vec': 'Wang2Vec', 'glove': 'GloVe', 'word2vec': 'Word2Vec', 'No': 'Sem Vetor', 'fasttext': 'FastText'}\n",
    "replacements_map = {**model_map, **representation_map, **embedding_type_map, **embedding_map}\n",
    "\n",
    "def get_group_csv(index_names, group_name, group_columns, target_value, index_map, dataframe=training_data_df, exported_columns=default_exported_columns):\n",
    "    if type(index_names) == str:\n",
    "        index_names = [index_names]\n",
    "    group = dataframe.groupby(group_columns).describe()[target_value].sort_values(by='mean', ascending=False)\n",
    "    for column in exported_columns:\n",
    "        group[column] = group[column] * 100\n",
    "    group.index.names = index_names\n",
    "    group = group.rename(index=index_map)\n",
    "    group.columns = renamed_columns\n",
    "    group.to_csv('grupo_' + group_name + '_50_epochs_mestrado_datalawyer_final.csv', columns=exported_columns_names, float_format = '%.2f%%')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contagem</th>\n",
       "      <th>F-Score</th>\n",
       "      <th>Desvio Padrão</th>\n",
       "      <th>Mínimo</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>Máximo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Representação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ELMo+GloVe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.565558</td>\n",
       "      <td>0.169473</td>\n",
       "      <td>91.445723</td>\n",
       "      <td>0.915056</td>\n",
       "      <td>0.915656</td>\n",
       "      <td>0.916255</td>\n",
       "      <td>91.685393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ELMo+Word2Vec-jur</td>\n",
       "      <td>2.0</td>\n",
       "      <td>91.361556</td>\n",
       "      <td>0.428542</td>\n",
       "      <td>91.058531</td>\n",
       "      <td>0.912100</td>\n",
       "      <td>0.913616</td>\n",
       "      <td>0.915131</td>\n",
       "      <td>91.664581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Contagem    F-Score  Desvio Padrão     Mínimo       25%  \\\n",
       "Representação                                                                \n",
       "ELMo+GloVe              2.0  91.565558       0.169473  91.445723  0.915056   \n",
       "ELMo+Word2Vec-jur       2.0  91.361556       0.428542  91.058531  0.912100   \n",
       "\n",
       "                        50%       75%     Máximo  \n",
       "Representação                                     \n",
       "ELMo+GloVe         0.915656  0.916255  91.685393  \n",
       "ELMo+Word2Vec-jur  0.913616  0.915131  91.664581  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_group_csv('Representação', REPRESENTATION, REPRESENTATION, TEST_F1_MEASURE, replacements_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = Path('/media/discoD/models/elmo/ner/mestrado/scores_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/discoD/models/elmo/ner/mestrado/scores_final'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2340a00345e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscores_wang2vec_selective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_wang2vec_total\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_glove_selective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_glove_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mscore_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'Wang2Vec'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'selective'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/discoD/anaconda3/envs/jurimetria/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/discoD/anaconda3/envs/jurimetria/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/discoD/models/elmo/ner/mestrado/scores_final'"
     ]
    }
   ],
   "source": [
    "scores_wang2vec_selective, scores_wang2vec_total, scores_glove_selective, scores_glove_total = [], [], [], []\n",
    "for score_file in scores_path.iterdir():\n",
    "    score = score_file.open(mode='r', encoding='utf8').readlines()[1].split()[-1]\n",
    "    if 'Wang2Vec' in score_file.name:\n",
    "        if 'selective' in score_file.name:\n",
    "            scores_wang2vec_selective.append(float(score))\n",
    "        elif 'total' in score_file.name:\n",
    "            scores_wang2vec_total.append(float(score))\n",
    "    elif 'GloVe' in score_file.name:\n",
    "        if 'selective' in score_file.name:\n",
    "            scores_glove_selective.append(float(score))\n",
    "        elif 'total' in score_file.name:\n",
    "            scores_glove_total.append(float(score))\n",
    "print(len(scores_wang2vec_selective))\n",
    "print(len(scores_wang2vec_total))\n",
    "print(len(scores_glove_selective))\n",
    "print(len(scores_glove_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statistics.mean(scores_wang2vec_selective))\n",
    "print(statistics.mean(scores_wang2vec_total))\n",
    "print(statistics.mean(scores_glove_selective))\n",
    "print(statistics.mean(scores_glove_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jurimetria",
   "language": "python",
   "name": "jurimetria"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
