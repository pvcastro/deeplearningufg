{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the topic coherence pipeline in Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `c_v` coherence for two different LDA models: a \"good\" and a \"bad\" LDA model. The good LDA model will be trained over 50 iterations and the bad one for 1 iteration. Hence in theory, the good LDA model will be able come up with better or more human-understandable topics. Therefore the coherence measure output for the good LDA model should be more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.DEBUG)\n",
    "\n",
    "import load_lee_background_corpus as load_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/home/Desenvolvimento/anaconda3/lib/python3.6/site-packages/gensim/test/test_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:06,203 : INFO : collecting all words and their counts\n",
      "2017-11-22 00:45:06,206 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-11-22 00:45:06,250 : INFO : collected 20429 word types from a corpus of 19878 words (unigram + bigrams) and 300 sentences\n",
      "2017-11-22 00:45:06,251 : INFO : using 20429 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning 300 training texts\n"
     ]
    }
   ],
   "source": [
    "texts = load_texts.get_train_texts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:09,085 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-11-22 00:45:09,125 : INFO : built Dictionary(4431 unique tokens: ['hundreds', 'people', 'homes', 'southern', 'highlands']...) from 300 documents (total 18861 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up two topic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be setting up two different LDA Topic models. A good one and bad one. To build a \"good\" topic model, we'll simply train it using more iterations than the bad one. Therefore the coherence should in theory be better for the good model than the bad one since it would be producing more \"human-interpretable\" topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:09,164 : INFO : using symmetric alpha at 0.1\n",
      "2017-11-22 00:45:09,168 : INFO : using symmetric eta at 0.00022568269013766644\n",
      "2017-11-22 00:45:09,172 : INFO : using serial LDA version on this node\n",
      "2017-11-22 00:45:09,654 : INFO : running online (multi-pass) LDA training, 10 topics, 5 passes over the supplied corpus of 300 documents, updating model once every 300 documents, evaluating perplexity every 300 documents, iterating 200x with a convergence threshold of 0.001000\n",
      "2017-11-22 00:45:09,656 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-11-22 00:45:10,280 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:13,727 : INFO : -11.613 per-word bound, 3132.8 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:13,730 : INFO : PROGRESS: pass 0, at document #300/300\n",
      "2017-11-22 00:45:13,732 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:16,011 : DEBUG : 225/300 documents converged within 200 iterations\n",
      "2017-11-22 00:45:16,013 : DEBUG : updating topics\n",
      "2017-11-22 00:45:16,179 : INFO : topic #8 (0.100): 0.009*\"commission\" + 0.007*\"australia\" + 0.007*\"company\" + 0.006*\"government\" + 0.005*\"sydney\" + 0.005*\"hih\" + 0.004*\"people\" + 0.004*\"day\" + 0.004*\"virus\" + 0.004*\"lockett\"\n",
      "2017-11-22 00:45:16,183 : INFO : topic #0 (0.100): 0.008*\"australia\" + 0.007*\"people\" + 0.006*\"government\" + 0.005*\"year\" + 0.005*\"action\" + 0.005*\"police\" + 0.004*\"president\" + 0.004*\"time\" + 0.004*\"nauru\" + 0.004*\"economy\"\n",
      "2017-11-22 00:45:16,184 : INFO : topic #9 (0.100): 0.009*\"government\" + 0.007*\"australia\" + 0.006*\"today\" + 0.006*\"area\" + 0.005*\"weapons\" + 0.005*\"year\" + 0.005*\"aircraft\" + 0.005*\"world_heritage\" + 0.004*\"terrorism\" + 0.004*\"projects\"\n",
      "2017-11-22 00:45:16,187 : INFO : topic #5 (0.100): 0.014*\"fire\" + 0.008*\"security\" + 0.006*\"firefighters\" + 0.006*\"sydney\" + 0.006*\"government\" + 0.005*\"arafat\" + 0.005*\"army\" + 0.005*\"today\" + 0.005*\"people\" + 0.005*\"fires\"\n",
      "2017-11-22 00:45:16,189 : INFO : topic #4 (0.100): 0.007*\"arafat\" + 0.007*\"israel\" + 0.007*\"united_states\" + 0.006*\"people\" + 0.006*\"station\" + 0.005*\"attacks\" + 0.005*\"space\" + 0.005*\"authority\" + 0.004*\"police\" + 0.004*\"new_york\"\n",
      "2017-11-22 00:45:16,191 : INFO : topic diff=7.024159, rho=1.000000\n",
      "2017-11-22 00:45:16,287 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:17,572 : INFO : -8.122 per-word bound, 278.7 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:17,573 : INFO : PROGRESS: pass 1, at document #300/300\n",
      "2017-11-22 00:45:17,575 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:18,074 : DEBUG : 300/300 documents converged within 200 iterations\n",
      "2017-11-22 00:45:18,076 : DEBUG : updating topics\n",
      "2017-11-22 00:45:18,269 : INFO : topic #1 (0.100): 0.011*\"metres\" + 0.009*\"australia\" + 0.005*\"event\" + 0.005*\"innings\" + 0.005*\"water\" + 0.005*\"test\" + 0.005*\"wicket\" + 0.004*\"adelaide\" + 0.004*\"economy\" + 0.004*\"child\"\n",
      "2017-11-22 00:45:18,271 : INFO : topic #4 (0.100): 0.008*\"arafat\" + 0.007*\"israel\" + 0.007*\"united_states\" + 0.006*\"station\" + 0.006*\"people\" + 0.005*\"attacks\" + 0.005*\"authority\" + 0.005*\"space\" + 0.005*\"security\" + 0.005*\"police\"\n",
      "2017-11-22 00:45:18,274 : INFO : topic #0 (0.100): 0.008*\"australia\" + 0.007*\"people\" + 0.006*\"year\" + 0.006*\"government\" + 0.005*\"action\" + 0.005*\"president\" + 0.004*\"police\" + 0.004*\"economy\" + 0.004*\"power\" + 0.004*\"minister\"\n",
      "2017-11-22 00:45:18,277 : INFO : topic #5 (0.100): 0.014*\"fire\" + 0.008*\"security\" + 0.006*\"firefighters\" + 0.006*\"sydney\" + 0.006*\"today\" + 0.005*\"army\" + 0.005*\"government\" + 0.005*\"new_south\" + 0.005*\"fires\" + 0.005*\"wales\"\n",
      "2017-11-22 00:45:18,279 : INFO : topic #9 (0.100): 0.009*\"government\" + 0.007*\"australia\" + 0.006*\"today\" + 0.006*\"area\" + 0.006*\"weapons\" + 0.006*\"aircraft\" + 0.005*\"world_heritage\" + 0.005*\"year\" + 0.004*\"terrorism\" + 0.004*\"projects\"\n",
      "2017-11-22 00:45:18,282 : INFO : topic diff=0.143650, rho=0.577350\n",
      "2017-11-22 00:45:18,386 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:19,684 : INFO : -8.041 per-word bound, 263.4 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:19,687 : INFO : PROGRESS: pass 2, at document #300/300\n",
      "2017-11-22 00:45:19,688 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:20,019 : DEBUG : 300/300 documents converged within 200 iterations\n",
      "2017-11-22 00:45:20,022 : DEBUG : updating topics\n",
      "2017-11-22 00:45:20,218 : INFO : topic #0 (0.100): 0.008*\"australia\" + 0.007*\"people\" + 0.006*\"year\" + 0.005*\"action\" + 0.005*\"government\" + 0.005*\"president\" + 0.004*\"economy\" + 0.004*\"police\" + 0.004*\"power\" + 0.004*\"minister\"\n",
      "2017-11-22 00:45:20,221 : INFO : topic #9 (0.100): 0.009*\"government\" + 0.007*\"australia\" + 0.006*\"weapons\" + 0.006*\"area\" + 0.006*\"aircraft\" + 0.006*\"today\" + 0.005*\"world_heritage\" + 0.005*\"year\" + 0.004*\"terrorism\" + 0.004*\"projects\"\n",
      "2017-11-22 00:45:20,223 : INFO : topic #2 (0.100): 0.013*\"australia\" + 0.011*\"afghanistan\" + 0.010*\"tora_bora\" + 0.008*\"people\" + 0.008*\"afghan\" + 0.008*\"police\" + 0.007*\"laden\" + 0.007*\"force\" + 0.006*\"radio\" + 0.006*\"united_states\"\n",
      "2017-11-22 00:45:20,226 : INFO : topic #5 (0.100): 0.015*\"fire\" + 0.008*\"security\" + 0.007*\"firefighters\" + 0.007*\"sydney\" + 0.006*\"today\" + 0.006*\"army\" + 0.005*\"new_south\" + 0.005*\"wales\" + 0.005*\"fires\" + 0.005*\"government\"\n",
      "2017-11-22 00:45:20,228 : INFO : topic #8 (0.100): 0.012*\"commission\" + 0.008*\"company\" + 0.006*\"hih\" + 0.006*\"australia\" + 0.006*\"government\" + 0.005*\"sydney\" + 0.005*\"report\" + 0.004*\"royal\" + 0.004*\"day\" + 0.004*\"people\"\n",
      "2017-11-22 00:45:20,230 : INFO : topic diff=0.111703, rho=0.500000\n",
      "2017-11-22 00:45:20,335 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:21,696 : INFO : -7.996 per-word bound, 255.4 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:21,698 : INFO : PROGRESS: pass 3, at document #300/300\n",
      "2017-11-22 00:45:21,701 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:22,067 : DEBUG : 300/300 documents converged within 200 iterations\n",
      "2017-11-22 00:45:22,070 : DEBUG : updating topics\n",
      "2017-11-22 00:45:22,266 : INFO : topic #4 (0.100): 0.008*\"arafat\" + 0.008*\"station\" + 0.007*\"israel\" + 0.007*\"united_states\" + 0.006*\"space\" + 0.006*\"security\" + 0.006*\"people\" + 0.006*\"authority\" + 0.006*\"attacks\" + 0.005*\"attack\"\n",
      "2017-11-22 00:45:22,267 : INFO : topic #7 (0.100): 0.013*\"taliban\" + 0.009*\"afghanistan\" + 0.008*\"government\" + 0.008*\"australia\" + 0.007*\"man\" + 0.007*\"forces\" + 0.006*\"india\" + 0.006*\"pakistan\" + 0.006*\"people\" + 0.005*\"united_states\"\n",
      "2017-11-22 00:45:22,269 : INFO : topic #1 (0.100): 0.011*\"metres\" + 0.011*\"australia\" + 0.006*\"test\" + 0.006*\"innings\" + 0.006*\"south_africa\" + 0.005*\"event\" + 0.005*\"adelaide\" + 0.005*\"wicket\" + 0.005*\"day\" + 0.005*\"water\"\n",
      "2017-11-22 00:45:22,272 : INFO : topic #5 (0.100): 0.015*\"fire\" + 0.007*\"security\" + 0.007*\"firefighters\" + 0.007*\"sydney\" + 0.006*\"today\" + 0.006*\"new_south\" + 0.006*\"wales\" + 0.006*\"fires\" + 0.005*\"army\" + 0.005*\"government\"\n",
      "2017-11-22 00:45:22,275 : INFO : topic #9 (0.100): 0.009*\"government\" + 0.007*\"australia\" + 0.006*\"aircraft\" + 0.006*\"weapons\" + 0.006*\"area\" + 0.005*\"today\" + 0.005*\"world_heritage\" + 0.005*\"year\" + 0.004*\"terrorism\" + 0.004*\"projects\"\n",
      "2017-11-22 00:45:22,278 : INFO : topic diff=0.089921, rho=0.447214\n",
      "2017-11-22 00:45:22,387 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:23,905 : INFO : -7.969 per-word bound, 250.5 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:23,906 : INFO : PROGRESS: pass 4, at document #300/300\n",
      "2017-11-22 00:45:23,908 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:24,281 : DEBUG : 300/300 documents converged within 200 iterations\n",
      "2017-11-22 00:45:24,283 : DEBUG : updating topics\n",
      "2017-11-22 00:45:24,470 : INFO : topic #2 (0.100): 0.013*\"australia\" + 0.012*\"afghanistan\" + 0.011*\"tora_bora\" + 0.009*\"afghan\" + 0.008*\"people\" + 0.008*\"force\" + 0.008*\"police\" + 0.008*\"laden\" + 0.007*\"radio\" + 0.006*\"united_states\"\n",
      "2017-11-22 00:45:24,473 : INFO : topic #8 (0.100): 0.013*\"commission\" + 0.008*\"company\" + 0.007*\"hih\" + 0.006*\"australia\" + 0.006*\"government\" + 0.006*\"report\" + 0.005*\"sydney\" + 0.005*\"royal\" + 0.004*\"people\" + 0.004*\"day\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:24,474 : INFO : topic #7 (0.100): 0.013*\"taliban\" + 0.010*\"afghanistan\" + 0.008*\"government\" + 0.008*\"australia\" + 0.008*\"man\" + 0.007*\"forces\" + 0.007*\"india\" + 0.006*\"pakistan\" + 0.006*\"people\" + 0.005*\"united_states\"\n",
      "2017-11-22 00:45:24,477 : INFO : topic #3 (0.100): 0.019*\"arafat\" + 0.011*\"israeli\" + 0.010*\"government\" + 0.008*\"people\" + 0.007*\"israel\" + 0.007*\"test\" + 0.007*\"sharon\" + 0.006*\"hamas\" + 0.006*\"attacks\" + 0.006*\"west_bank\"\n",
      "2017-11-22 00:45:24,480 : INFO : topic #1 (0.100): 0.012*\"australia\" + 0.011*\"metres\" + 0.007*\"test\" + 0.006*\"south_africa\" + 0.006*\"innings\" + 0.005*\"adelaide\" + 0.005*\"day\" + 0.005*\"event\" + 0.005*\"wicket\" + 0.005*\"water\"\n",
      "2017-11-22 00:45:24,482 : INFO : topic diff=0.070731, rho=0.408248\n",
      "2017-11-22 00:45:24,484 : INFO : using symmetric alpha at 0.1\n",
      "2017-11-22 00:45:24,487 : INFO : using symmetric eta at 0.00022568269013766644\n",
      "2017-11-22 00:45:24,490 : INFO : using serial LDA version on this node\n",
      "2017-11-22 00:45:25,015 : INFO : running online (single-pass) LDA training, 10 topics, 1 passes over the supplied corpus of 300 documents, updating model once every 300 documents, evaluating perplexity every 300 documents, iterating 1x with a convergence threshold of 0.001000\n",
      "2017-11-22 00:45:25,019 : WARNING : too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
      "2017-11-22 00:45:25,750 : DEBUG : bound: at document #0\n",
      "2017-11-22 00:45:26,994 : INFO : -11.904 per-word bound, 3832.9 perplexity estimate based on a held-out corpus of 300 documents with 18861 words\n",
      "2017-11-22 00:45:26,995 : INFO : PROGRESS: pass 0, at document #300/300\n",
      "2017-11-22 00:45:26,997 : DEBUG : performing inference on a chunk of 300 documents\n",
      "2017-11-22 00:45:27,094 : DEBUG : 0/300 documents converged within 1 iterations\n",
      "2017-11-22 00:45:27,097 : DEBUG : updating topics\n",
      "2017-11-22 00:45:27,206 : INFO : topic #1 (0.100): 0.009*\"australia\" + 0.007*\"people\" + 0.005*\"government\" + 0.004*\"arafat\" + 0.004*\"afghanistan\" + 0.004*\"security\" + 0.004*\"company\" + 0.004*\"sydney\" + 0.003*\"united_states\" + 0.003*\"year\"\n",
      "2017-11-22 00:45:27,209 : INFO : topic #5 (0.100): 0.007*\"government\" + 0.005*\"australia\" + 0.005*\"people\" + 0.004*\"afghanistan\" + 0.004*\"today\" + 0.004*\"police\" + 0.004*\"arafat\" + 0.003*\"security\" + 0.003*\"time\" + 0.003*\"year\"\n",
      "2017-11-22 00:45:27,211 : INFO : topic #9 (0.100): 0.006*\"australia\" + 0.006*\"government\" + 0.005*\"people\" + 0.005*\"police\" + 0.004*\"year\" + 0.004*\"today\" + 0.004*\"afghanistan\" + 0.004*\"time\" + 0.003*\"security\" + 0.003*\"arafat\"\n",
      "2017-11-22 00:45:27,213 : INFO : topic #6 (0.100): 0.008*\"australia\" + 0.006*\"government\" + 0.006*\"people\" + 0.004*\"afghanistan\" + 0.004*\"security\" + 0.004*\"arafat\" + 0.004*\"police\" + 0.004*\"year\" + 0.003*\"day\" + 0.003*\"company\"\n",
      "2017-11-22 00:45:27,215 : INFO : topic #7 (0.100): 0.006*\"people\" + 0.005*\"australia\" + 0.005*\"government\" + 0.004*\"fire\" + 0.004*\"united_states\" + 0.004*\"today\" + 0.004*\"security\" + 0.003*\"police\" + 0.003*\"arafat\" + 0.003*\"year\"\n",
      "2017-11-22 00:45:27,217 : INFO : topic diff=2.620431, rho=1.000000\n"
     ]
    }
   ],
   "source": [
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=200, passes=5, num_topics=10)\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the pipeline parameters for one coherence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:27,232 : DEBUG : Setting topics to those of the model: LdaModel(num_terms=4431, num_topics=10, decay=0.5, chunksize=2000)\n",
      "2017-11-22 00:45:27,239 : DEBUG : Setting topics to those of the model: LdaModel(num_terms=4431, num_topics=10, decay=0.5, chunksize=2000)\n"
     ]
    }
   ],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline parameters for C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_set at 0x1a11e1ee18>, prob=<function p_boolean_sliding_window at 0x1a11e32048>, conf=<function cosine_similarity at 0x1a11e7ae18>, aggr=<function arithmetic_mean at 0x1a11e74400>)\n"
     ]
    }
   ],
   "source": [
    "print(goodcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print coherence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:27,269 : INFO : using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n",
      "2017-11-22 00:45:27,436 : DEBUG : completed batch 0; 64 documents processed (92 virtual)\n",
      "2017-11-22 00:45:27,504 : DEBUG : completed batch 0; 64 documents processed (258 virtual)\n",
      "2017-11-22 00:45:27,549 : DEBUG : completed batch 0; 64 documents processed (305 virtual)\n",
      "2017-11-22 00:45:27,555 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:27,562 : DEBUG : finished all batches; 64 documents processed (305 virtual)\n",
      "2017-11-22 00:45:27,566 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:27,572 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:27,649 : DEBUG : completed batch 1; 107 documents processed (484 virtual)\n",
      "2017-11-22 00:45:27,652 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:27,653 : DEBUG : completed batch 1; 128 documents processed (332 virtual)\n",
      "2017-11-22 00:45:27,655 : DEBUG : finished all batches; 107 documents processed (484 virtual)\n",
      "2017-11-22 00:45:27,656 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:27,658 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:27,661 : DEBUG : finished all batches; 128 documents processed (332 virtual)\n",
      "2017-11-22 00:45:27,664 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:27,662 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:27,668 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:27,722 : INFO : 3 accumulators retrieved from output queue\n",
      "2017-11-22 00:45:27,765 : INFO : accumulated word occurrence stats for 1121 virtual documents\n",
      "2017-11-22 00:45:28,691 : INFO : using ParallelWordOccurrenceAccumulator(processes=3, batch_size=64) to estimate probabilities from sliding windows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.372587195389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-11-22 00:45:28,761 : DEBUG : completed batch 0; 64 documents processed (92 virtual)\n",
      "2017-11-22 00:45:28,797 : DEBUG : completed batch 0; 64 documents processed (305 virtual)\n",
      "2017-11-22 00:45:28,801 : DEBUG : completed batch 0; 64 documents processed (258 virtual)\n",
      "2017-11-22 00:45:28,807 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:28,810 : DEBUG : finished all batches; 64 documents processed (258 virtual)\n",
      "2017-11-22 00:45:28,813 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:28,832 : DEBUG : completed batch 1; 128 documents processed (333 virtual)\n",
      "2017-11-22 00:45:28,819 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:28,836 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:28,846 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:28,839 : DEBUG : finished all batches; 128 documents processed (333 virtual)\n",
      "2017-11-22 00:45:28,842 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:28,870 : DEBUG : completed batch 1; 105 documents processed (528 virtual)\n",
      "2017-11-22 00:45:28,889 : DEBUG : observed sentinel value; terminating\n",
      "2017-11-22 00:45:28,894 : DEBUG : finished all batches; 105 documents processed (528 virtual)\n",
      "2017-11-22 00:45:28,898 : INFO : serializing accumulator to return to master...\n",
      "2017-11-22 00:45:28,908 : INFO : accumulator serialized\n",
      "2017-11-22 00:45:28,928 : INFO : 3 accumulators retrieved from output queue\n",
      "2017-11-22 00:45:28,948 : INFO : accumulated word occurrence stats for 1119 virtual documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.272436160451\n"
     ]
    }
   ],
   "source": [
    "print(goodcm.get_coherence())\n",
    "print(badcm.get_coherence())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
