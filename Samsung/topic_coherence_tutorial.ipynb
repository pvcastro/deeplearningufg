{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration of the topic coherence pipeline in Gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `u_mass` and `c_v` coherence for two different LDA models: a \"good\" and a \"bad\" LDA model. The good LDA model will be trained over 50 iterations and the bad one for 1 iteration. Hence in theory, the good LDA model will be able come up with better or more human-understandable topics. Therefore the coherence measure output for the good LDA model should be more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/home/Desenvolvimento/anaconda3/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n",
      "/Users/home/Desenvolvimento/anaconda3/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:20: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in table 2 from [this](http://www.cs.bham.ac.uk/~pxt/IDA/lsa_ind.pdf) paper, this corpus essentially has two classes of documents. First five are about human-computer interaction and the other four are about graphs. We will be setting up two LDA models. One with 50 iterations of training and the other with just 1. Hence the one with 50 iterations (\"better\" model) should be able to capture this underlying pattern of the corpus better than the \"bad\" LDA model. Therefore, in theory, our topic coherence for the good LDA model should be greater than the one for the bad LDA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [['human', 'interface', 'computer'],\n",
    "         ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
    "         ['eps', 'user', 'interface', 'system'],\n",
    "         ['system', 'human', 'system', 'eps'],\n",
    "         ['user', 'response', 'time'],\n",
    "         ['trees'],\n",
    "         ['graph', 'trees'],\n",
    "         ['graph', 'minors', 'trees'],\n",
    "         ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['human', 'interface', 'computer', 'survey', 'user']...)\n",
      "[[(0, 1), (1, 1), (2, 1)], [(2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(1, 1), (4, 1), (5, 1), (8, 1)], [(0, 1), (5, 2), (8, 1)], [(4, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(3, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(texts)\n",
    "print(dictionary)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up two topic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be setting up two different LDA Topic models. A good one and bad one. To build a \"good\" topic model, we'll simply train it using more iterations than the bad one. Therefore the `u_mass` coherence should in theory be better for the good model than the bad one since it would be producing more \"human-interpretable\" topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=50, num_topics=2)\n",
    "badLdaModel = LdaModel(corpus=corpus, id2word=dictionary, iterations=1, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using U_Mass Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "badcm = CoherenceModel(model=badLdaModel, corpus=corpus, dictionary=dictionary, coherence='u_mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the pipeline parameters for one coherence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the pipeline parameters for `u_mass` coherence. By pipeline parameters, we mean the functions being used to calculate segmentation, probability estimation, confirmation measure and aggregation as shown in figure 1 in [this](http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_pre at 0x1163abe18>, prob=<function p_boolean_document at 0x116372d08>, conf=<function log_conditional_probability at 0x116407c80>, aggr=<function arithmetic_mean at 0x116408488>)\n"
     ]
    }
   ],
   "source": [
    "print(goodcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see below using LDA visualization, the better model comes up with two topics composed of the following words:\n",
    "1. goodLdaModel:\n",
    "    - __Topic 1__: More weightage assigned to words such as \"system\", \"user\", \"eps\", \"interface\" etc which captures the first set of documents.\n",
    "    - __Topic 2__: More weightage assigned to words such as \"graph\", \"trees\", \"survey\" which captures the topic in the second set of documents.\n",
    "2. badLdaModel:\n",
    "    - __Topic 1__: More weightage assigned to words such as \"system\", \"user\", \"trees\", \"graph\" which doesn't make the topic clear enough.\n",
    "    - __Topic 2__: More weightage assigned to words such as \"system\", \"trees\", \"graph\", \"user\" which is similar to the first topic. Hence both topics are not human-interpretable.\n",
    "\n",
    "Therefore, the topic coherence for the goodLdaModel should be greater for this than the badLdaModel since the topics it comes up with are more human-interpretable. We will see this using `u_mass` and `c_v` topic coherence measures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el245747566387205136489243\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el245747566387205136489243_data = {\"mdsDat\": {\"Freq\": [65.03477089258136, 34.96522910741864], \"cluster\": [1, 1], \"topics\": [1, 2], \"x\": [0.024834160005609375, -0.024834160005609375], \"y\": [0.0, 0.0]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.1851448894800507, 1.8547029723971382, 2.170511155643144, 1.5304475759172556, 1.5169146735139878, 1.4179953449556353, 1.4073409826043264, 1.3505997574554758, 1.6856076442035397, 1.221697889385895, 0.9516758201540783, 0.5674448531380688, 1.256343299653482, 1.5516257976546797, 0.8421633521437427, 1.0870045769357466, 0.7605610270599303, 0.7246405553895667, 0.7178957288546797, 0.6552740824272296, 0.6467069738369734, 0.7800326566109199, 0.44143458585692663, 0.6762338047275285], \"Term\": [\"graph\", \"minors\", \"trees\", \"survey\", \"interface\", \"response\", \"human\", \"time\", \"system\", \"computer\", \"user\", \"eps\", \"system\", \"eps\", \"user\", \"computer\", \"time\", \"human\", \"response\", \"interface\", \"trees\", \"survey\", \"graph\", \"minors\", \"minors\", \"graph\", \"survey\", \"trees\", \"interface\", \"response\", \"human\", \"time\", \"computer\", \"user\", \"eps\", \"system\"], \"Total\": [2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.861378694207579, 2.296137558254065, 2.9505438122540637, 2.177154549754229, 2.1721887559412174, 2.135891073810315, 2.131981537993893, 2.1111607845154063, 2.772612221139286, 2.063861241529638, 2.503301617808758, 1.823788152791551, 1.823788152791551, 2.503301617808758, 2.063861241529638, 2.772612221139286, 2.1111607845154063, 2.131981537993893, 2.135891073810315, 2.1721887559412174, 2.177154549754229, 2.9505438122540637, 2.296137558254065, 3.861378694207579], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2377, 0.2167, 0.1232, 0.0778, 0.0712, 0.0206, 0.0149, -0.0164, -0.0674, -0.0941, -0.5369, -0.7373, 0.6781, 0.5725, 0.1545, 0.1145, 0.0299, -0.0283, -0.0395, -0.1476, -0.1631, -0.2796, -0.5981, -0.6914], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -1.7785, -2.3193, -2.1621, -2.5115, -2.5204, -2.5878, -2.5953, -2.6365, -2.4149, -2.7368, -2.9866, -3.5037, -2.0883, -1.8772, -2.4883, -2.2331, -2.5902, -2.6386, -2.6479, -2.7392, -2.7523, -2.5649, -3.1342, -2.7077]}, \"token.table\": {\"Topic\": [1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.9186302369878944, 0.4593151184939472, 0.8710279542314346, 0.3994724378740029, 0.7989448757480058, 0.4681886694793165, 0.4681886694793165, 0.47367306523247066, 0.47367306523247066, 0.5483092970361534, 0.5483092970361534, 0.4690472136737914, 0.4690472136737914, 0.48452869789775527, 0.48452869789775527, 0.7769245747640018, 0.25897485825466726, 0.920730297737589, 0.4603651488687945, 0.7213414067612332, 0.3606707033806166, 0.6778411463316326, 0.3389205731658163], \"Term\": [\"computer\", \"computer\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"R\": 12, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el245747566387205136489243\", ldavis_el245747566387205136489243_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el245747566387205136489243\", ldavis_el245747566387205136489243_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el245747566387205136489243\", ldavis_el245747566387205136489243_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "0      65.034771        1       1  0.024834  0.0\n",
       "1      34.965229        1       2 -0.024834  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "10    Default  2.000000      graph  2.000000  12.0000  12.0000\n",
       "11    Default  1.000000     minors  1.000000  11.0000  11.0000\n",
       "9     Default  2.000000      trees  2.000000  10.0000  10.0000\n",
       "3     Default  2.000000     survey  2.000000   9.0000   9.0000\n",
       "1     Default  2.000000  interface  2.000000   8.0000   8.0000\n",
       "6     Default  2.000000   response  2.000000   7.0000   7.0000\n",
       "0     Default  2.000000      human  2.000000   6.0000   6.0000\n",
       "7     Default  2.000000       time  2.000000   5.0000   5.0000\n",
       "5     Default  3.000000     system  3.000000   4.0000   4.0000\n",
       "2     Default  2.000000   computer  2.000000   3.0000   3.0000\n",
       "4     Default  2.000000       user  2.000000   2.0000   2.0000\n",
       "8     Default  2.000000        eps  2.000000   1.0000   1.0000\n",
       "5      Topic1  3.185145     system  3.861379   0.2377  -1.7785\n",
       "8      Topic1  1.854703        eps  2.296138   0.2167  -2.3193\n",
       "4      Topic1  2.170511       user  2.950544   0.1232  -2.1621\n",
       "2      Topic1  1.530448   computer  2.177155   0.0778  -2.5115\n",
       "7      Topic1  1.516915       time  2.172189   0.0712  -2.5204\n",
       "0      Topic1  1.417995      human  2.135891   0.0206  -2.5878\n",
       "6      Topic1  1.407341   response  2.131982   0.0149  -2.5953\n",
       "1      Topic1  1.350600  interface  2.111161  -0.0164  -2.6365\n",
       "9      Topic1  1.685608      trees  2.772612  -0.0674  -2.4149\n",
       "3      Topic1  1.221698     survey  2.063861  -0.0941  -2.7368\n",
       "10     Topic1  0.951676      graph  2.503302  -0.5369  -2.9866\n",
       "11     Topic1  0.567445     minors  1.823788  -0.7373  -3.5037\n",
       "11     Topic2  1.256343     minors  1.823788   0.6781  -2.0883\n",
       "10     Topic2  1.551626      graph  2.503302   0.5725  -1.8772\n",
       "3      Topic2  0.842163     survey  2.063861   0.1545  -2.4883\n",
       "9      Topic2  1.087005      trees  2.772612   0.1145  -2.2331\n",
       "1      Topic2  0.760561  interface  2.111161   0.0299  -2.5902\n",
       "6      Topic2  0.724641   response  2.131982  -0.0283  -2.6386\n",
       "0      Topic2  0.717896      human  2.135891  -0.0395  -2.6479\n",
       "7      Topic2  0.655274       time  2.172189  -0.1476  -2.7392\n",
       "2      Topic2  0.646707   computer  2.177155  -0.1631  -2.7523\n",
       "4      Topic2  0.780033       user  2.950544  -0.2796  -2.5649\n",
       "8      Topic2  0.441435        eps  2.296138  -0.5981  -3.1342\n",
       "5      Topic2  0.676234     system  3.861379  -0.6914  -2.7077, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "2         1  0.918630   computer\n",
       "2         2  0.459315   computer\n",
       "8         1  0.871028        eps\n",
       "10        1  0.399472      graph\n",
       "10        2  0.798945      graph\n",
       "0         1  0.468189      human\n",
       "0         2  0.468189      human\n",
       "1         1  0.473673  interface\n",
       "1         2  0.473673  interface\n",
       "11        1  0.548309     minors\n",
       "11        2  0.548309     minors\n",
       "6         1  0.469047   response\n",
       "6         2  0.469047   response\n",
       "3         1  0.484529     survey\n",
       "3         2  0.484529     survey\n",
       "5         1  0.776925     system\n",
       "5         2  0.258975     system\n",
       "7         1  0.920730       time\n",
       "7         2  0.460365       time\n",
       "9         1  0.721341      trees\n",
       "9         2  0.360671      trees\n",
       "4         1  0.677841       user\n",
       "4         2  0.338921       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(goodLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el245747569353283260445876\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el245747569353283260445876_data = {\"mdsDat\": {\"Freq\": [50.10587487093828, 49.894125129061706], \"cluster\": [1, 1], \"topics\": [1, 2], \"x\": [0.00992462473974599, -0.00992462473974599], \"y\": [0.0, 0.0]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"Freq\": [2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.5477035395886969, 1.2910812134468375, 1.2482610683394364, 2.044810351474935, 1.145948781648506, 1.4345642686604465, 0.9683677134420566, 1.2440042132985265, 0.9128796507193929, 0.8855208630332231, 0.8210695323427468, 0.9864925165772992, 1.8067541897559787, 1.2806497846723315, 1.2215833746923948, 1.196510418824563, 1.5707576433663986, 1.1456583941005238, 1.3961189162024636, 0.982914257292388, 1.5145652756291756, 0.8891501812534693, 0.8499076672631741, 0.614726184375034], \"Term\": [\"interface\", \"graph\", \"response\", \"eps\", \"system\", \"computer\", \"minors\", \"trees\", \"survey\", \"time\", \"human\", \"user\", \"interface\", \"eps\", \"computer\", \"system\", \"human\", \"user\", \"time\", \"trees\", \"survey\", \"minors\", \"response\", \"graph\", \"graph\", \"response\", \"minors\", \"survey\", \"trees\", \"time\", \"user\", \"human\", \"system\", \"computer\", \"eps\", \"interface\"], \"Total\": [2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.162429723963731, 2.1409888807100117, 2.1374112495929056, 3.5593756271041106, 2.128863038940894, 2.8306831848629104, 2.1140261075425806, 2.814761856664925, 2.109390069543956, 2.107104237725618, 2.1017193170150783, 2.793246706333278, 2.793246706333278, 2.1017193170150783, 2.107104237725618, 2.109390069543956, 2.814761856664925, 2.1140261075425806, 2.8306831848629104, 2.128863038940894, 3.5593756271041106, 2.1374112495929056, 2.1409888807100117, 2.162429723963731], \"loglift\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3566, 0.1852, 0.1532, 0.1368, 0.0717, 0.0114, -0.0897, -0.1255, -0.1465, -0.1759, -0.2489, -0.3498, 0.2596, 0.1999, 0.1501, 0.1283, 0.1119, 0.0827, -0.0116, -0.0776, -0.1592, -0.1818, -0.2286, -0.5625], \"logprob\": [12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.2395, -2.4208, -2.4545, -1.961, -2.54, -2.3154, -2.7084, -2.4579, -2.7674, -2.7978, -2.8734, -2.6899, -2.0805, -2.4247, -2.4719, -2.4926, -2.2205, -2.536, -2.3383, -2.6893, -2.2569, -2.7895, -2.8347, -3.1586]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2], \"Freq\": [0.4678556829858837, 0.4678556829858837, 0.467073887683327, 0.467073887683327, 0.35800632924139725, 0.7160126584827945, 0.4697343049825781, 0.4697343049825781, 0.924885547879911, 0.4624427739399555, 0.47458496931285543, 0.47458496931285543, 0.47580092731898593, 0.47580092731898593, 0.47407068727511226, 0.47407068727511226, 0.5618963013541759, 0.5618963013541759, 0.4730310550244035, 0.4730310550244035, 0.3552698419698111, 0.7105396839396222, 0.3532716078392326, 0.3532716078392326], \"Term\": [\"computer\", \"computer\", \"eps\", \"eps\", \"graph\", \"graph\", \"human\", \"human\", \"interface\", \"interface\", \"minors\", \"minors\", \"response\", \"response\", \"survey\", \"survey\", \"system\", \"system\", \"time\", \"time\", \"trees\", \"trees\", \"user\", \"user\"]}, \"R\": 12, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el245747569353283260445876\", ldavis_el245747569353283260445876_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el245747569353283260445876\", ldavis_el245747569353283260445876_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el245747569353283260445876\", ldavis_el245747569353283260445876_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x    y\n",
       "topic                                           \n",
       "1      50.105875        1       1  0.009925  0.0\n",
       "0      49.894125        1       2 -0.009925  0.0, topic_info=     Category      Freq       Term     Total  loglift  logprob\n",
       "term                                                          \n",
       "1     Default  2.000000  interface  2.000000  12.0000  12.0000\n",
       "10    Default  2.000000      graph  2.000000  11.0000  11.0000\n",
       "6     Default  2.000000   response  2.000000  10.0000  10.0000\n",
       "8     Default  2.000000        eps  2.000000   9.0000   9.0000\n",
       "5     Default  3.000000     system  3.000000   8.0000   8.0000\n",
       "2     Default  2.000000   computer  2.000000   7.0000   7.0000\n",
       "11    Default  2.000000     minors  2.000000   6.0000   6.0000\n",
       "9     Default  2.000000      trees  2.000000   5.0000   5.0000\n",
       "3     Default  2.000000     survey  2.000000   4.0000   4.0000\n",
       "7     Default  2.000000       time  2.000000   3.0000   3.0000\n",
       "0     Default  2.000000      human  2.000000   2.0000   2.0000\n",
       "4     Default  2.000000       user  2.000000   1.0000   1.0000\n",
       "1      Topic1  1.547704  interface  2.162430   0.3566  -2.2395\n",
       "8      Topic1  1.291081        eps  2.140989   0.1852  -2.4208\n",
       "2      Topic1  1.248261   computer  2.137411   0.1532  -2.4545\n",
       "5      Topic1  2.044810     system  3.559376   0.1368  -1.9610\n",
       "0      Topic1  1.145949      human  2.128863   0.0717  -2.5400\n",
       "4      Topic1  1.434564       user  2.830683   0.0114  -2.3154\n",
       "7      Topic1  0.968368       time  2.114026  -0.0897  -2.7084\n",
       "9      Topic1  1.244004      trees  2.814762  -0.1255  -2.4579\n",
       "3      Topic1  0.912880     survey  2.109390  -0.1465  -2.7674\n",
       "11     Topic1  0.885521     minors  2.107104  -0.1759  -2.7978\n",
       "6      Topic1  0.821070   response  2.101719  -0.2489  -2.8734\n",
       "10     Topic1  0.986493      graph  2.793247  -0.3498  -2.6899\n",
       "10     Topic2  1.806754      graph  2.793247   0.2596  -2.0805\n",
       "6      Topic2  1.280650   response  2.101719   0.1999  -2.4247\n",
       "11     Topic2  1.221583     minors  2.107104   0.1501  -2.4719\n",
       "3      Topic2  1.196510     survey  2.109390   0.1283  -2.4926\n",
       "9      Topic2  1.570758      trees  2.814762   0.1119  -2.2205\n",
       "7      Topic2  1.145658       time  2.114026   0.0827  -2.5360\n",
       "4      Topic2  1.396119       user  2.830683  -0.0116  -2.3383\n",
       "0      Topic2  0.982914      human  2.128863  -0.0776  -2.6893\n",
       "5      Topic2  1.514565     system  3.559376  -0.1592  -2.2569\n",
       "2      Topic2  0.889150   computer  2.137411  -0.1818  -2.7895\n",
       "8      Topic2  0.849908        eps  2.140989  -0.2286  -2.8347\n",
       "1      Topic2  0.614726  interface  2.162430  -0.5625  -3.1586, token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "2         1  0.467856   computer\n",
       "2         2  0.467856   computer\n",
       "8         1  0.467074        eps\n",
       "8         2  0.467074        eps\n",
       "10        1  0.358006      graph\n",
       "10        2  0.716013      graph\n",
       "0         1  0.469734      human\n",
       "0         2  0.469734      human\n",
       "1         1  0.924886  interface\n",
       "1         2  0.462443  interface\n",
       "11        1  0.474585     minors\n",
       "11        2  0.474585     minors\n",
       "6         1  0.475801   response\n",
       "6         2  0.475801   response\n",
       "3         1  0.474071     survey\n",
       "3         2  0.474071     survey\n",
       "5         1  0.561896     system\n",
       "5         2  0.561896     system\n",
       "7         1  0.473031       time\n",
       "7         2  0.473031       time\n",
       "9         1  0.355270      trees\n",
       "9         2  0.710540      trees\n",
       "4         1  0.353272       user\n",
       "4         2  0.353272       user, R=12, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.gensim.prepare(badLdaModel, corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.6676987064\n",
      "-14.7076308762\n"
     ]
    }
   ],
   "source": [
    "print(goodcm.get_coherence())\n",
    "print(badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "goodcm = CoherenceModel(model=goodLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "badcm = CoherenceModel(model=badLdaModel, texts=texts, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline parameters for C_V coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence_Measure(seg=<function s_one_set at 0x10d5b5f28>, prob=<function p_boolean_sliding_window at 0x10d5a8e18>, conf=<function cosine_similarity at 0x10d60eea0>, aggr=<function arithmetic_mean at 0x10d611488>)\n"
     ]
    }
   ],
   "source": [
    "print(goodcm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print coherence values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.383841355374\n",
      "0.383841355374\n"
     ]
    }
   ],
   "source": [
    "print(goodcm.get_coherence())\n",
    "print(badcm.get_coherence())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence as we can see, the `u_mass` and `c_v` coherence for the good LDA model is much more (better) than that for the bad LDA model. This is because, simply, the good LDA model usually comes up with better topics that are more human interpretable. The badLdaModel however fails to decipher between these two topics and comes up with topics which are not clear to a human. The `u_mass` and `c_v` topic coherences capture this wonderfully by giving the interpretability of these topics a number as we can see above. Hence this coherence measure can be used to compare difference topic models based on their human-interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
