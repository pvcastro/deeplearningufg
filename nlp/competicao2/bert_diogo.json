local train_data = "train.conll";
local dev_data = "dev.conll";

local transformer_model = "neuralmind/bert-base-portuguese-cased";
local max_length = 512;

local num_epochs = std.parseInt(std.extVar('num_epochs'));
local batch_size = std.parseInt(std.extVar('batch_size'));
local lr = std.parseJson(std.extVar('lr'));



{
  "dataset_reader": {
    "type": "conll2003",
    "tag_label": "ner",
    "coding_scheme": "IOB1",
    "token_indexers": {
      "tokens": {
        "type": "pretrained_transformer_mismatched",
        "model_name": transformer_model,
        "max_length": max_length,
        "tokenizer_kwargs":  {"max_len": max_length}
      },
    },
  },
  "train_data_path": train_data,
  "validation_data_path": dev_data,
  "model": {
    "type": "crf_tagger",
    "label_encoding": "IOB1",
    "constrain_crf_decoding": true,
    "calculate_span_f1": true,
    "dropout": 0.5,
    "include_start_end_transitions": false,
    "text_field_embedder": {
      "token_embedders": {
        "tokens": {
            "type": "pretrained_transformer_mismatched",
            "model_name": transformer_model,
            "max_length": max_length,
            "tokenizer_kwargs":  {"max_len": max_length}
        },
       },
    },
    "encoder": {
        "type": "lstm",
        "input_size": 768,
        "hidden_size": 200,
        "num_layers": 2,
        "dropout": 0.5,
        "bidirectional": true
    },
  },
  "data_loader": {
    "batch_sampler":{
      "type": "bucket",
      "batch_size": batch_size,
      "sorting_keys":[
        "tokens"
      ]
    }
  },
  trainer: {
    optimizer: {
        type: "huggingface_adamw",
        weight_decay: 0.1,
        lr: lr ,
    },
    "learning_rate_scheduler":{
        "type": "slanted_triangular",
        "cut_frac": 0.06,
    },
    "validation_metric": "+f1-measure-overall",
    "num_epochs": num_epochs,
  }
}