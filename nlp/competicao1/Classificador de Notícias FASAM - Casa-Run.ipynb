{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pt_core_news_sm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = Path('../dataset/functions_classifier')\n",
    "# train_data_path = data_path / 'train.jsonl'\n",
    "# validation_data_path = data_path /'dev.jsonl'\n",
    "# test_data_path = data_path /'test.jsonl'\n",
    "validation_data_path = 'df_valid.jsonl'\n",
    "train_data_path = 'df_train.jsonl'\n",
    "validation_title_data_path = 'df_valid_title.jsonl'\n",
    "train_title_data_path = 'df_train_title.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(train_data_path, orient='records', lines=True)\n",
    "dev_df = pd.read_json(validation_data_path, orient='records', lines=True)\n",
    "train_title_df = pd.read_json(train_title_data_path, orient='records', lines=True)\n",
    "dev_title_df = pd.read_json(validation_title_data_path, orient='records', lines=True)\n",
    "#test_df = pd.read_json(test_data_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7894, 94918)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_counts = count_vect.fit_transform(train_df['text'])\n",
    "train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7894, 94918)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf = tfidf_transformer.fit_transform(train_counts)\n",
    "train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935949618446822"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', max_iter=1000, tol=1e-4, random_state=42))])\n",
    "\n",
    "text_clf_svm = text_clf_svm.fit(train_df['text'], train_df['label'])\n",
    "predicted_svm = text_clf_svm.predict(train_df['text'])\n",
    "balanced_accuracy_score(train_df['label'], predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(predictions, out_path):\n",
    "    count = 0\n",
    "\n",
    "    with open(out_path, mode='w', encoding='utf-8') as out_file:\n",
    "        print('Saving predictions for %s' % validation_data_path)\n",
    "        out_file.write('id,category\\n')\n",
    "        idx = 0\n",
    "        for result in predictions:\n",
    "            count += 1\n",
    "            out_file.write(str(idx) + ',' + result + '\\n')\n",
    "            idx += 1\n",
    "            if count % 100 == 0:\n",
    "                print('Predicted %d sentences' % count)\n",
    "    out_file.close()\n",
    "    print('Finished predicting %d sentences' % count)\n",
    "    print('Results saved in %s' % Path(out_path).absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions for df_valid.jsonl\n",
      "Predicted 100 sentences\n",
      "Predicted 200 sentences\n",
      "Predicted 300 sentences\n",
      "Predicted 400 sentences\n",
      "Predicted 500 sentences\n",
      "Predicted 600 sentences\n",
      "Predicted 700 sentences\n",
      "Predicted 800 sentences\n",
      "Predicted 900 sentences\n",
      "Predicted 1000 sentences\n",
      "Predicted 1100 sentences\n",
      "Predicted 1200 sentences\n",
      "Predicted 1300 sentences\n",
      "Predicted 1400 sentences\n",
      "Predicted 1500 sentences\n",
      "Predicted 1600 sentences\n",
      "Predicted 1700 sentences\n",
      "Predicted 1800 sentences\n",
      "Predicted 1900 sentences\n",
      "Predicted 2000 sentences\n",
      "Predicted 2100 sentences\n",
      "Predicted 2200 sentences\n",
      "Predicted 2300 sentences\n",
      "Predicted 2400 sentences\n",
      "Predicted 2500 sentences\n",
      "Predicted 2600 sentences\n",
      "Predicted 2700 sentences\n",
      "Predicted 2800 sentences\n",
      "Predicted 2900 sentences\n",
      "Predicted 3000 sentences\n",
      "Predicted 3100 sentences\n",
      "Predicted 3200 sentences\n",
      "Predicted 3300 sentences\n",
      "Predicted 3400 sentences\n",
      "Predicted 3500 sentences\n",
      "Predicted 3600 sentences\n",
      "Predicted 3700 sentences\n",
      "Predicted 3800 sentences\n",
      "Predicted 3900 sentences\n",
      "Predicted 4000 sentences\n",
      "Predicted 4100 sentences\n",
      "Predicted 4200 sentences\n",
      "Finished predicting 4251 sentences\n",
      "Results saved in /media/discoD/Mestrado/FASAM/submissions_text_clf_svm.csv\n"
     ]
    }
   ],
   "source": [
    "write_predictions(text_clf_svm.predict(dev_df['text']), 'submissions_text_clf_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [line.replace('\\n', '') for line in open('stopwords-pt.txt', mode='r', encoding='utf8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945251613575733"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_clf_svm = Pipeline([('vect', CountVectorizer(stop_words=stopwords)), ('tfidf', TfidfTransformer()),\n",
    "                              ('clf-svm', SGDClassifier(loss='hinge', max_iter=2000, tol=1e-5, random_state=42))])\n",
    "\n",
    "processed_clf_svm = processed_clf_svm.fit(train_df['text'], train_df['label'])\n",
    "predicted_svm = processed_clf_svm.predict(train_df['text'])\n",
    "balanced_accuracy_score(train_df['label'], predicted_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions for df_valid.jsonl\n",
      "Predicted 100 sentences\n",
      "Predicted 200 sentences\n",
      "Predicted 300 sentences\n",
      "Predicted 400 sentences\n",
      "Predicted 500 sentences\n",
      "Predicted 600 sentences\n",
      "Predicted 700 sentences\n",
      "Predicted 800 sentences\n",
      "Predicted 900 sentences\n",
      "Predicted 1000 sentences\n",
      "Predicted 1100 sentences\n",
      "Predicted 1200 sentences\n",
      "Predicted 1300 sentences\n",
      "Predicted 1400 sentences\n",
      "Predicted 1500 sentences\n",
      "Predicted 1600 sentences\n",
      "Predicted 1700 sentences\n",
      "Predicted 1800 sentences\n",
      "Predicted 1900 sentences\n",
      "Predicted 2000 sentences\n",
      "Predicted 2100 sentences\n",
      "Predicted 2200 sentences\n",
      "Predicted 2300 sentences\n",
      "Predicted 2400 sentences\n",
      "Predicted 2500 sentences\n",
      "Predicted 2600 sentences\n",
      "Predicted 2700 sentences\n",
      "Predicted 2800 sentences\n",
      "Predicted 2900 sentences\n",
      "Predicted 3000 sentences\n",
      "Predicted 3100 sentences\n",
      "Predicted 3200 sentences\n",
      "Predicted 3300 sentences\n",
      "Predicted 3400 sentences\n",
      "Predicted 3500 sentences\n",
      "Predicted 3600 sentences\n",
      "Predicted 3700 sentences\n",
      "Predicted 3800 sentences\n",
      "Predicted 3900 sentences\n",
      "Predicted 4000 sentences\n",
      "Predicted 4100 sentences\n",
      "Predicted 4200 sentences\n",
      "Finished predicting 4251 sentences\n",
      "Results saved in /media/discoD/Mestrado/FASAM/submissions_stop_clf_svm.csv\n"
     ]
    }
   ],
   "source": [
    "write_predictions(processed_clf_svm.predict(dev_df['text']), 'submissions_stop_clf_svm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998515118784651"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_clf_svc = Pipeline([('vect', CountVectorizer(stop_words=stopwords)), ('tfidf', TfidfTransformer()),\n",
    "                              ('clf-svm', LinearSVC(max_iter=2000, tol=1e-5, random_state=42))])\n",
    "\n",
    "processed_clf_svc = processed_clf_svc.fit(train_df['text'], train_df['label'])\n",
    "predicted_svc = processed_clf_svc.predict(train_df['text'])\n",
    "balanced_accuracy_score(train_df['label'], predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions for df_valid.jsonl\n",
      "Predicted 100 sentences\n",
      "Predicted 200 sentences\n",
      "Predicted 300 sentences\n",
      "Predicted 400 sentences\n",
      "Predicted 500 sentences\n",
      "Predicted 600 sentences\n",
      "Predicted 700 sentences\n",
      "Predicted 800 sentences\n",
      "Predicted 900 sentences\n",
      "Predicted 1000 sentences\n",
      "Predicted 1100 sentences\n",
      "Predicted 1200 sentences\n",
      "Predicted 1300 sentences\n",
      "Predicted 1400 sentences\n",
      "Predicted 1500 sentences\n",
      "Predicted 1600 sentences\n",
      "Predicted 1700 sentences\n",
      "Predicted 1800 sentences\n",
      "Predicted 1900 sentences\n",
      "Predicted 2000 sentences\n",
      "Predicted 2100 sentences\n",
      "Predicted 2200 sentences\n",
      "Predicted 2300 sentences\n",
      "Predicted 2400 sentences\n",
      "Predicted 2500 sentences\n",
      "Predicted 2600 sentences\n",
      "Predicted 2700 sentences\n",
      "Predicted 2800 sentences\n",
      "Predicted 2900 sentences\n",
      "Predicted 3000 sentences\n",
      "Predicted 3100 sentences\n",
      "Predicted 3200 sentences\n",
      "Predicted 3300 sentences\n",
      "Predicted 3400 sentences\n",
      "Predicted 3500 sentences\n",
      "Predicted 3600 sentences\n",
      "Predicted 3700 sentences\n",
      "Predicted 3800 sentences\n",
      "Predicted 3900 sentences\n",
      "Predicted 4000 sentences\n",
      "Predicted 4100 sentences\n",
      "Predicted 4200 sentences\n",
      "Finished predicting 4251 sentences\n",
      "Results saved in /media/discoD/Mestrado/FASAM/submissions_stop_clf_svc.csv\n"
     ]
    }
   ],
   "source": [
    "write_predictions(processed_clf_svc.predict(dev_df['text']), 'submissions_stop_clf_svc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987754918365435"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_clf_svc = Pipeline([('tfidf_vect', TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2), stop_words=stopwords)),\n",
    "                              ('clf-svm', LinearSVC(max_iter=2000, tol=1e-5, random_state=42))])\n",
    "\n",
    "processed_clf_svc = processed_clf_svc.fit(train_df['text'], train_df['label'])\n",
    "predicted_svc = processed_clf_svc.predict(train_df['text'])\n",
    "balanced_accuracy_score(train_df['label'], predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving predictions for df_valid.jsonl\n",
      "Predicted 100 sentences\n",
      "Predicted 200 sentences\n",
      "Predicted 300 sentences\n",
      "Predicted 400 sentences\n",
      "Predicted 500 sentences\n",
      "Predicted 600 sentences\n",
      "Predicted 700 sentences\n",
      "Predicted 800 sentences\n",
      "Predicted 900 sentences\n",
      "Predicted 1000 sentences\n",
      "Predicted 1100 sentences\n",
      "Predicted 1200 sentences\n",
      "Predicted 1300 sentences\n",
      "Predicted 1400 sentences\n",
      "Predicted 1500 sentences\n",
      "Predicted 1600 sentences\n",
      "Predicted 1700 sentences\n",
      "Predicted 1800 sentences\n",
      "Predicted 1900 sentences\n",
      "Predicted 2000 sentences\n",
      "Predicted 2100 sentences\n",
      "Predicted 2200 sentences\n",
      "Predicted 2300 sentences\n",
      "Predicted 2400 sentences\n",
      "Predicted 2500 sentences\n",
      "Predicted 2600 sentences\n",
      "Predicted 2700 sentences\n",
      "Predicted 2800 sentences\n",
      "Predicted 2900 sentences\n",
      "Predicted 3000 sentences\n",
      "Predicted 3100 sentences\n",
      "Predicted 3200 sentences\n",
      "Predicted 3300 sentences\n",
      "Predicted 3400 sentences\n",
      "Predicted 3500 sentences\n",
      "Predicted 3600 sentences\n",
      "Predicted 3700 sentences\n",
      "Predicted 3800 sentences\n",
      "Predicted 3900 sentences\n",
      "Predicted 4000 sentences\n",
      "Predicted 4100 sentences\n",
      "Predicted 4200 sentences\n",
      "Finished predicting 4251 sentences\n",
      "Results saved in /media/discoD/Mestrado/FASAM/submissions_linear_svc_ngram.csv\n"
     ]
    }
   ],
   "source": [
    "write_predictions(processed_clf_svc.predict(dev_df['text']), 'submissions_linear_svc_ngram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998515118784651"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_clf_svc = Pipeline([('tfidf_vect', TfidfVectorizer(sublinear_tf=True, ngram_range=(1, 2), stop_words=stopwords)),\n",
    "                              ('clf-svm', LinearSVC(max_iter=2000, tol=1e-5, random_state=42))])\n",
    "\n",
    "processed_clf_svc = processed_clf_svc.fit(train_df['text'], train_df['label'])\n",
    "predicted_svc = processed_clf_svc.predict(train_df['text'])\n",
    "balanced_accuracy_score(train_df['label'], predicted_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allennlp",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
