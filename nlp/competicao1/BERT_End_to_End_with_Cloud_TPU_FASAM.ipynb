{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rkTLZ3I4_7c_"
   },
   "source": [
    "# BERT End to End (Fine-tuning + Predicting) in 5 minutes with Cloud TPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1wtjs1QDb3DX"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**BERT**, or **B**idirectional **E**mbedding **R**epresentations from **T**ransformers, is a new method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. The academic paper can be found here: https://arxiv.org/abs/1810.04805.\n",
    "\n",
    "This Colab demonstates using a free Colab Cloud TPU to fine-tune sentence and sentence-pair classification tasks built on top of pretrained BERT models and \n",
    "run predictions on tuned model. The colab demonsrates loading pretrained BERT models from both [TF Hub](https://www.tensorflow.org/hub) and checkpoints.\n",
    "\n",
    "**Note:**  You will need a GCP (Google Compute Engine) account and a GCS (Google Cloud \n",
    "Storage) bucket for this Colab to run.\n",
    "\n",
    "Please follow the [Google Cloud TPU quickstart](https://cloud.google.com/tpu/docs/quickstart) for how to create GCP account and GCS bucket. You have [$300 free credit](https://cloud.google.com/free/) to get started with any GCP product. You can learn more about Cloud TPU at https://cloud.google.com/tpu/docs.\n",
    "\n",
    "This notebook is hosted on GitHub. To view it in its original repository, after opening the notebook, select **File > View on GitHub**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjiKRZ_faLRy"
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "In this notebook, you will learn how to train and evaluate a BERT model using TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ld-JXlueIuPH"
   },
   "source": [
    "## Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "POkof5uHaQ_c"
   },
   "source": [
    "<h3><a href=\"https://cloud.google.com/tpu/\"><img valign=\"middle\" src=\"https://raw.githubusercontent.com/GoogleCloudPlatform/tensorflow-without-a-phd/master/tensorflow-rl-pong/images/tpu-hexagon.png\" width=\"50\"></a>  &nbsp;&nbsp;Train on TPU</h3>\n",
    "\n",
    "   1. Create a Cloud Storage bucket for your TensorBoard logs at http://console.cloud.google.com/storage and fill in the BUCKET parameter in the \"Parameters\" section below.\n",
    " \n",
    "   1. On the main menu, click Runtime and select **Change runtime type**. Set \"TPU\" as the hardware accelerator.\n",
    "   1. Click Runtime again and select **Runtime > Run All** (Watch out: the \"Colab-only auth for this notebook and the TPU\" cell requires user input). You can also run the cells manually with Shift-ENTER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UdMmwCJFaT8F"
   },
   "source": [
    "### Set up your TPU environment\n",
    "\n",
    "In this section, you perform the following tasks:\n",
    "\n",
    "*   Set up a Colab TPU running environment\n",
    "*   Verify that you are connected to a TPU device\n",
    "*   Upload your credentials to TPU to access your GCS bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "191zq3ZErihP",
    "outputId": "d1d783e7-da40-4e7d-e5b1-83ceaefe6892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU address is grpc://10.29.214.2:8470\n",
      "TPU devices:\n",
      "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 15424681047144544699),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13813547154624671566),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 12869142696822744466),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12651457877795909178),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12636266837984255050),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15850439552621819954),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 6773820945566904616),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 15789355259147257011),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 9519591032810665737),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14672640977589511959),\n",
      " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 10353152115491394183)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0716 20:05:27.122159 139877051504512 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "import string\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
    "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "print('TPU address is', TPU_ADDRESS)\n",
    "\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "with tf.Session(TPU_ADDRESS) as session:\n",
    "  print('TPU devices:')\n",
    "  pprint.pprint(session.list_devices())\n",
    "\n",
    "  # Upload credentials to TPU.\n",
    "  with open('/content/adc.json', 'r') as f:\n",
    "    auth_info = json.load(f)\n",
    "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
    "  # Now credentials are set for all future sessions on this TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HUBP35oCDmbF"
   },
   "source": [
    "### Prepare and import BERT modules\n",
    "​\n",
    "With your environment configured, you can now prepare and import the BERT modules. The following step clones the source code from GitHub and import the modules from the source. Alternatively, you can install BERT using pip (!pip install bert-tensorflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "7wzwke0sxS6W",
    "outputId": "ef0dc10b-dd68-4cf5-9799-f69fb3f1566c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 20:05:32.011282 139877051504512 deprecation_wrapper.py:119] From bert_repo/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n",
    "if not 'bert_repo' in sys.path:\n",
    "  sys.path += ['bert_repo']\n",
    "\n",
    "# import python modules defined by BERT\n",
    "import modeling\n",
    "import optimization\n",
    "import run_classifier\n",
    "import run_classifier_with_tfhub\n",
    "import tokenization\n",
    "\n",
    "# import tfhub \n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DxM-eYNt1gwp"
   },
   "source": [
    "###Preparação do dataset e conversão para formato BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rDKzB3_N1fwX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "WjtcXOM72qRv",
    "outputId": "8a7ebd56-d88f-43b1-c592-02bc83282f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  df_train.csv.zip\n",
      "replace df_train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
      "  inflating: df_train.csv            \n",
      "Archive:  df_valid.csv.zip\n",
      "replace df_valid.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
      "  inflating: df_valid.csv            \n"
     ]
    }
   ],
   "source": [
    "!unzip df_train.csv.zip\n",
    "!unzip df_valid.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "mst3G9Ev1tqt",
    "outputId": "2cd2b8a6-7813-4357-cda9-010f7c1485eb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casa da Barra Funda tem clima roceiro e receit...</td>\n",
       "      <td>No Quem Quer Pão 75, casa de clima roceiro em ...</td>\n",
       "      <td>comida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professores de SP decidem manter greve; grupo ...</td>\n",
       "      <td>Professores da rede estadual decidiram manter ...</td>\n",
       "      <td>educacao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Em segunda edição, concurso paga R$ 35 mil par...</td>\n",
       "      <td>O Prêmio FedEx para Pequenas Empresas está com...</td>\n",
       "      <td>empreendedorsocial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Usar maconha por anos não faz tão mal para a s...</td>\n",
       "      <td>No esforço de entender os efeitos da maconha s...</td>\n",
       "      <td>equilibrioesaude</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Baleia-azul percorre 5.200 km e revela a cient...</td>\n",
       "      <td>Isabela, uma baleia-azul, ajudou os cientistas...</td>\n",
       "      <td>ciencia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  ...            category\n",
       "0  Casa da Barra Funda tem clima roceiro e receit...  ...              comida\n",
       "1  Professores de SP decidem manter greve; grupo ...  ...            educacao\n",
       "2  Em segunda edição, concurso paga R$ 35 mil par...  ...  empreendedorsocial\n",
       "3  Usar maconha por anos não faz tão mal para a s...  ...    equilibrioesaude\n",
       "4  Baleia-azul percorre 5.200 km e revela a cient...  ...             ciencia\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    " \n",
    "df = pd.read_csv(\"df_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "FQpFLOy910qm",
    "outputId": "b13b5983-f777-48e7-fb0e-329fdadfa001"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>textao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comida</td>\n",
       "      <td>casa da barra funda tem clima roceiro e receit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>educacao</td>\n",
       "      <td>professores de sp decidem manter greve grupo f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>empreendedorsocial</td>\n",
       "      <td>em segunda edição concurso paga r 35 mil para ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>equilibrioesaude</td>\n",
       "      <td>usar maconha por anos não faz tão mal para a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ciencia</td>\n",
       "      <td>baleiaazul percorre 5200 km e revela a cientis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                             textao\n",
       "0              comida  casa da barra funda tem clima roceiro e receit...\n",
       "1            educacao  professores de sp decidem manter greve grupo f...\n",
       "2  empreendedorsocial  em segunda edição concurso paga r 35 mil para ...\n",
       "3    equilibrioesaude  usar maconha por anos não faz tão mal para a s...\n",
       "4             ciencia  baleiaazul percorre 5200 km e revela a cientis..."
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].str.strip()\n",
    "df['title']=df['title'].str.lower()\n",
    "df['text']=df['text'].str.lower()\n",
    "df[\"title\"] = df['title'].str.replace('[^\\w\\s]','')\n",
    "df[\"text\"] = df['text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#Concatenando title e text\n",
    "df['textao'] = df.apply(lambda x: x['title'] + ' ' + x['text'], 1)\n",
    "df = df.drop(['title', 'text'], 1)\n",
    "\n",
    "#pegando apenas os 150 primeiros caracteres \n",
    "#df[\"textao\"] = df[\"textao\"].str.slice(0,150)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "pehgJbds2J3g",
    "outputId": "8d7f9d03-f1f6-4aed-d512-3525d6f9da6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>label</th>\n",
       "      <th>alpha</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>1037</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>cães da usp escapam de distrofia muscular e po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>a</td>\n",
       "      <td>mães que trabalham fora têm filhos mais educad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>4254</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>análise de dna de esqueletos muda teoria sobre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7122</th>\n",
       "      <td>7122</td>\n",
       "      <td>6</td>\n",
       "      <td>a</td>\n",
       "      <td>novo brooklin chega à vila cordeiro próxima a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>5213</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>pontos turísticos da itália são fechados depoi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  label alpha                                               text\n",
       "1037     1037      5     a  cães da usp escapam de distrofia muscular e po...\n",
       "191       191      5     a  mães que trabalham fora têm filhos mais educad...\n",
       "4254     4254      1     a  análise de dna de esqueletos muda teoria sobre...\n",
       "7122     7122      6     a   novo brooklin chega à vila cordeiro próxima a...\n",
       "5213     5213      8     a  pontos turísticos da itália são fechados depoi..."
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating train and dev dataframes according to BERT\n",
    "df_bert = pd.DataFrame({'user_id':range(len(df)),\n",
    "            'label':le.fit_transform(df['category']), #encoder da categoria para número 0,1,2,3...\n",
    "            'alpha':['a']*df.shape[0],\n",
    "            'text':df['textao'].replace(r'\\n',' ',regex=True).replace(r'\\t','',regex=True).replace(r'\\\"','',regex=True).replace(r'\\'','',regex=True)})\n",
    " \n",
    "df_bert_train, df_bert_dev = train_test_split(df_bert, test_size=0.25)\n",
    "df_bert_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cYt81XI16-v"
   },
   "outputs": [],
   "source": [
    "# Creating test dataframe according to BERT\n",
    "df_test = pd.read_csv(\"df_valid.csv\")\n",
    "df_test['text'] = df_test['text'].str.strip()\n",
    "df_test['title']=df_test['title'].str.lower()\n",
    "df_test['text']=df_test['text'].str.lower()\n",
    "df_test[\"title\"] = df_test['title'].str.replace('[^\\w\\s]','')\n",
    "df_test[\"text\"] = df_test['text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "#df_test['textao'] = df_test.apply(lambda x: x['title'] + ' ' + x['text'], 1)\n",
    "#df_test = df_test.drop(['title', 'text'], 1)\n",
    "\n",
    "#pegando apenas os 300 primeiros caracteres \n",
    "#df_test[\"textao\"] = df[\"textao\"].str.slice(0,300)\n",
    "\n",
    "df_bert_test = pd.DataFrame({'User_ID':range(len(df_test)),\n",
    "                 'text':df_test['text'].replace(r'\\n',' ',regex=True).replace(r'\\t','',regex=True).replace(r'\\\"','',regex=True).replace(r'\\'','',regex=True)})\n",
    " \n",
    "# Saving dataframes to .tsv format as required by BERT\n",
    "df_bert_train.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
    "df_bert_dev.to_csv('dev.tsv', sep='\\t', index=False, header=False)\n",
    "df_bert_test.to_csv('test.tsv', sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RRu1aKO1D7-Z"
   },
   "source": [
    "### Prepare for training\n",
    "\n",
    "This next section of code performs the following tasks:\n",
    "\n",
    "*  Specify task and download training data.\n",
    "*  Specify BERT pretrained model\n",
    "*  Specify GS bucket, create output directory for model checkpoints and eval results.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "tYkaAlJNfhul",
    "outputId": "b0116d2e-49f9-49b9-c5ce-0a126977f003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Task data directory: ./ *****\n",
      "adc.json   df_train.csv      df_valid.csv.zip\t   test_results.tsv\n",
      "bert_repo  df_train.csv.zip  sample_data\t   test.tsv\n",
      "dev.tsv    df_valid.csv      submission_valid.csv  train.tsv\n",
      "***** Model output directory: gs://pln-bert01/bert-tfhub/models/CoLA *****\n"
     ]
    }
   ],
   "source": [
    "TASK = 'CoLA' #@param {type:\"string\"}\n",
    "assert TASK in ('MRPC', 'CoLA'), 'Only (MRPC, CoLA) are demonstrated here.'\n",
    "\n",
    "# Download glue data.\n",
    "#! test -d download_glue_repo || git clone https://gist.github.com/60c2bdb54d156a41194446737ce03e2e.git download_glue_repo\n",
    "#!python download_glue_repo/download_glue_data.py --data_dir='glue_data' --tasks=$TASK\n",
    "#!unzip glue_data.zip\n",
    "\n",
    "TASK_DATA_DIR = './'\n",
    "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
    "!ls $TASK_DATA_DIR\n",
    "\n",
    "BUCKET = 'pln-bert01' #@param {type:\"string\"}\n",
    "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
    "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
    "\n",
    "# Available pretrained model checkpoints:\n",
    "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
    "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
    "#   cased_L-12_H-768_A-12: cased BERT large model\n",
    "#   bert_multi_cased_L-12_H-768_A-12: novo\n",
    "BERT_MODEL = 'multi_cased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
    "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hcpfl4N2EdOk"
   },
   "source": [
    "Now let's load tokenizer module from TF Hub and play with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "TylDOYd-6AH-",
    "outputId": "a1fe374b-6dfa-4403-a876-dbc364445085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['um',\n",
       " 'EX',\n",
       " '##EM',\n",
       " '##P',\n",
       " '##L',\n",
       " '##O',\n",
       " 'de',\n",
       " 'tok',\n",
       " '##eni',\n",
       " '##zação',\n",
       " 'com',\n",
       " 'a',\n",
       " 'rede',\n",
       " 'Bert']"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = run_classifier_with_tfhub.create_tokenizer_from_hub_module(BERT_MODEL_HUB)\n",
    "tokenizer.tokenize(\"um EXEMPLO de tokenização com a rede Bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oqQ_LHyzcoYW"
   },
   "source": [
    "Also we initilize our hyperprams, prepare the training data and initialize TPU config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYVYULZiKvUi"
   },
   "outputs": [],
   "source": [
    "TRAIN_BATCH_SIZE = 16\n",
    "EVAL_BATCH_SIZE = 8\n",
    "PREDICT_BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-6\n",
    "NUM_TRAIN_EPOCHS = 14.0\n",
    "MAX_SEQ_LENGTH = 200\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.18\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 1000\n",
    "SAVE_SUMMARY_STEPS = 500\n",
    "\n",
    "processors = {\n",
    "  \"cola\": run_classifier.ColaProcessor,\n",
    "  \"mnli\": run_classifier.MnliProcessor,\n",
    "  \"mrpc\": run_classifier.MrpcProcessor,\n",
    "}\n",
    "processor = processors[TASK.lower()]()\n",
    "label_list = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "\n",
    "# Compute number of train and warmup steps from batch size\n",
    "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
    "num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "# Setup TPU related config\n",
    "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
    "NUM_TPU_CORES = 8\n",
    "ITERATIONS_PER_LOOP = 1000\n",
    "\n",
    "def get_run_config(output_dir):\n",
    "  return tf.contrib.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=output_dir,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
    "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m3iFMeqLaSll"
   },
   "source": [
    "# Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eXyJRc0OIHEU"
   },
   "source": [
    "This section demonstrates fine-tuning from a pre-trained BERT TF Hub module and running predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "nwcsdbLuIX2I",
    "outputId": "a4a4edab-5f8e-407e-b48c-057e695e9371"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 20:46:26.754944 139877051504512 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f375553bf28>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Force TF Hub writes to the GS bucket we provide.\n",
    "os.environ['TFHUB_CACHE_DIR'] = OUTPUT_DIR\n",
    "\n",
    "model_fn = run_classifier_with_tfhub.model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps,\n",
    "  use_tpu=True,\n",
    "  bert_hub_module_handle=BERT_MODEL_HUB\n",
    ")\n",
    "\n",
    "estimator_from_tfhub = tf.contrib.tpu.TPUEstimator(\n",
    "  use_tpu=True,\n",
    "  model_fn=model_fn,\n",
    "  config=get_run_config(OUTPUT_DIR),\n",
    "  train_batch_size=TRAIN_BATCH_SIZE,\n",
    "  eval_batch_size=EVAL_BATCH_SIZE,\n",
    "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGVYj_rlcDhc"
   },
   "source": [
    "At this point, you can now fine-tune the model, evaluate it, and run predictions on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5U_c8s2AvhgL"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "def model_train(estimator):\n",
    "  print('MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...')\n",
    "  # We'll set sequences to be at most 128 tokens long.\n",
    "  train_features = run_classifier.convert_examples_to_features(\n",
    "      train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  print('***** Started training at {} *****'.format(datetime.datetime.now()))\n",
    "  print('  Num examples = {}'.format(len(train_examples)))\n",
    "  print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n",
    "  tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "  train_input_fn = run_classifier.input_fn_builder(\n",
    "      features=train_features,\n",
    "      seq_length=MAX_SEQ_LENGTH,\n",
    "      is_training=True,\n",
    "      drop_remainder=True)\n",
    "  estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "  print('***** Finished training at {} *****'.format(datetime.datetime.now()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TRhzyk4_WD2n",
    "outputId": "106b9a8f-4377-4e6f-85c3-bd441773780f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...\n",
      "***** Started training at 2019-07-16 20:47:36.857741 *****\n",
      "  Num examples = 5920\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0716 20:47:50.881925 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.884044 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.887786 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.890632 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.901534 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.913112 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.922306 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.929311 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.932483 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.953958 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.957013 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.964368 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.969183 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.976100 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.979266 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.995989 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:50.999153 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.010890 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.014108 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.024225 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.028498 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.037762 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.041291 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.050183 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.055777 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.067421 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.073257 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.080612 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.085369 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.093682 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.097882 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.117968 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.122940 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.133787 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.136896 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.147995 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.153458 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.161632 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.166840 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.175448 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.180406 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.190861 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.195935 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.203033 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.208126 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.214059 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.218490 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.234183 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.238050 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.249797 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.255070 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.263279 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.268950 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.277943 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.281168 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.291041 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.294351 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.309192 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.316620 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.323212 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.328027 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.335051 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.338256 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.356446 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.359487 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.369887 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.373507 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.381944 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.385933 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.395547 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.398972 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.407891 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.411368 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.425171 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.428485 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.435787 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.439541 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.446696 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.450440 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.469595 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.473200 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.484575 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.487947 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.498531 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.503979 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.512245 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.516665 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.526974 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.531601 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.541624 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.546037 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.552573 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.556875 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.564232 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.568568 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.584644 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.587921 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.599720 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.603697 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.614439 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.619296 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.627926 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.631283 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.641533 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.645354 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.656687 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.660467 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.666094 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.669400 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.678715 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.682754 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.700127 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.703804 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.716959 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.721922 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.731699 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.736390 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.745217 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.748688 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.758833 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.762573 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.774290 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.777830 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.785456 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.789296 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.795957 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.799416 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.817978 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.821544 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.833188 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.836870 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.846482 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.850596 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.860989 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.864683 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.875478 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.879708 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.895228 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.899549 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.908964 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.912761 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.920344 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.923970 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.941143 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.944306 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.956351 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.960218 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.970004 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.974286 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.983965 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.987429 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:51.997155 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.001105 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.013270 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.016870 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.025018 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.028587 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.036302 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.041866 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.057790 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.061503 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.073029 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.076844 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.087477 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.093020 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.102014 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.105894 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.115755 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.119623 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.131006 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.134835 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.142293 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.147838 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.153764 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.158142 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.174875 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.178143 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.190216 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.193592 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.204851 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.210106 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.219027 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.222184 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.235025 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.240211 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.252964 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.256538 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.264344 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.268356 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.274899 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.278493 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.296582 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.300431 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.310386 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.314266 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.324224 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.329277 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.338806 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.342350 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.353923 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.358801 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.392598 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.396005 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.410138 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.413987 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.425309 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.429070 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:47:52.438404 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Finished training at 2019-07-16 20:52:23.392451 *****\n"
     ]
    }
   ],
   "source": [
    "model_train(estimator_from_tfhub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eoXRtSPZvdiS"
   },
   "outputs": [],
   "source": [
    "def model_eval(estimator):\n",
    "  # Eval the model.\n",
    "  eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
    "  eval_features = run_classifier.convert_examples_to_features(\n",
    "      eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  print('***** Started evaluation at {} *****'.format(datetime.datetime.now()))\n",
    "  print('  Num examples = {}'.format(len(eval_examples)))\n",
    "  print('  Batch size = {}'.format(EVAL_BATCH_SIZE))\n",
    "\n",
    "  # Eval will be slightly WRONG on the TPU because it will truncate\n",
    "  # the last batch.\n",
    "  eval_steps = int(len(eval_examples) / EVAL_BATCH_SIZE)\n",
    "  eval_input_fn = run_classifier.input_fn_builder(\n",
    "      features=eval_features,\n",
    "      seq_length=MAX_SEQ_LENGTH,\n",
    "      is_training=False,\n",
    "      drop_remainder=True)\n",
    "  result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
    "  print('***** Finished evaluation at {} *****'.format(datetime.datetime.now()))\n",
    "  output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
    "  with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
    "    print(\"***** Eval results *****\")\n",
    "    for key in sorted(result.keys()):\n",
    "      print('  {} = {}'.format(key, str(result[key])))\n",
    "      writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lLQehBr4WHjj",
    "outputId": "b4cfb8cb-f2c1-44e4-e2eb-98e505abda57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Started evaluation at 2019-07-16 20:53:14.877564 *****\n",
      "  Num examples = 1974\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0716 20:53:24.321354 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.323379 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/input_mask) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.325229 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/segment_ids) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.326941 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/mlm_positions) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.334302 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/word_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.351061 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/token_type_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.362904 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/position_embeddings) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.369917 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.373661 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/embeddings/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.393786 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.397068 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.404466 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.408619 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.417982 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.421377 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.436642 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.440037 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.447532 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.451575 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.461488 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.465487 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.476246 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.479471 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.485669 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.490387 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_0/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.501914 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.505094 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.513702 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.517160 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.525515 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.529694 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.549003 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.554143 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.560806 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.563765 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.574150 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.578846 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.590115 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.595289 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.602002 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.606823 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_1/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.619169 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.623956 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.631732 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.636925 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.644947 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.650353 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.665749 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.669457 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.679281 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.682528 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.693837 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.697781 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.709054 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.712457 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.718494 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.722745 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_2/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.735743 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.739417 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.746939 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.751020 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.761940 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.765532 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.781121 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.784210 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.790455 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.795288 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.808538 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.813405 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.823669 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.826817 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.834628 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.837914 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_3/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.851186 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.854593 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.863379 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.868578 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.875801 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.879419 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.896097 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.899243 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.908009 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.912649 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.925960 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.929920 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.940393 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.943758 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.950355 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.955634 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_4/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.967825 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.970989 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.978281 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.981600 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.989521 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:24.994068 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.011867 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.016287 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.021935 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.025790 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.036691 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.040687 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.051222 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.054676 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.060245 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.064737 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_5/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.079713 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.083151 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.090855 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.094941 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.105227 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.108158 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.131516 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.135313 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.142514 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.147480 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.156676 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.163604 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.172858 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.176099 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.182816 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.187754 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_6/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.199639 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.203382 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.211970 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.217104 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.225382 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.229565 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.247221 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.253253 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.259738 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.263755 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.272836 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.276779 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.286947 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.290417 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.296657 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.301466 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_7/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.314657 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.317717 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.328259 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.332521 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.341210 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.344643 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.360396 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.363725 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.371113 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.375854 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.386353 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.392724 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.402566 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.405817 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.413107 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.420862 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_8/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.433747 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.439151 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.447052 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.450287 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.458998 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.463601 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.478885 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.482145 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.487519 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.492099 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.504053 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.509454 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.519896 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.523125 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.529103 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.534005 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_9/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.545911 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.549187 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.559031 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.563357 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.571283 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.577946 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.595045 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.598457 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.605481 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.608974 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.619194 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.624386 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.634148 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.637602 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.647156 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.650455 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_10/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.665237 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.668425 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/query/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.675693 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.679140 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/key/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.686624 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.689953 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/self/value/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.708079 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.711418 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.717022 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.720496 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/attention/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.731179 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.735017 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/intermediate/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.746352 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.750023 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.756027 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.759793 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/encoder/layer_11/output/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.795108 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.798805 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/bert/pooler/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.818957 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/kernel) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.822135 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/dense/bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.831584 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/beta) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.834965 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/transform/LayerNorm/gamma) is not supported on the TPU. Execution will fail if this op is used in the graph. \n",
      "E0716 20:53:25.845633 139877051504512 tpu.py:376] Operation of type Placeholder (module_apply_tokens/cls/predictions/output_bias) is not supported on the TPU. Execution will fail if this op is used in the graph. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Finished evaluation at 2019-07-16 20:54:13.862395 *****\n",
      "***** Eval results *****\n",
      "  eval_accuracy = 0.9273374\n",
      "  eval_loss = 0.41927478\n",
      "  global_step = 5180\n",
      "  loss = 0.18559228\n"
     ]
    }
   ],
   "source": [
    "model_eval(estimator_from_tfhub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3_afEMR3dfa"
   },
   "outputs": [],
   "source": [
    "def model_predict(estimator):\n",
    "  # Make predictions on a subset of eval examples\n",
    "  prediction_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
    "  #[:PREDICT_BATCH_SIZE]\n",
    "  #prediction_examples = processor.get_dev_examples(TASK_DATA_DIR)[:PREDICT_BATCH_SIZE]\n",
    "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "\n",
    "  for example, prediction in zip(prediction_examples, predictions):\n",
    "    print('text_a: %s\\ntext_b: %s\\nlabel:%s\\nprediction:%s\\n' % (example.text_a, example.text_b, str(example.label), prediction['probabilities']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynDmeatCWLJK"
   },
   "outputs": [],
   "source": [
    "model_predict(estimator_from_tfhub) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mml5ELUaajmp"
   },
   "source": [
    "# Fine-tune and run predictions on a pre-trained BERT model from checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xtgLSuh8IdGP"
   },
   "source": [
    "Alternatively, you can also load pre-trained BERT models from saved checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "uu2dQ_TId-uH",
    "outputId": "ec66f27c-7d68-4e92-851a-885c007680db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** BERT pretrained directory: gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12 *****\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/bert_config.json\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt.index\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/vocab.txt\n",
      "gs://pln-bert01/bert/multi_cased_L-12_H-768_A-12/vocab_teste.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 20:54:38.843158 139877051504512 estimator.py:1984] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f375553b950>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "# Setup task specific model and TPU running config.\n",
    "BERT_PRETRAINED_DIR = 'gs://pln-bert01/bert/' + BERT_MODEL \n",
    "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
    "!gsutil ls $BERT_PRETRAINED_DIR\n",
    "\n",
    "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
    "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
    "\n",
    "model_fn = run_classifier.model_fn_builder(\n",
    "  bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
    "  num_labels=len(label_list),\n",
    "  init_checkpoint=INIT_CHECKPOINT,\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps,\n",
    "  use_tpu=True,\n",
    "  use_one_hot_embeddings=True\n",
    ")\n",
    "\n",
    "OUTPUT_DIR = OUTPUT_DIR.replace('bert-tfhub', 'bert-checkpoints')\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "\n",
    "estimator_from_checkpoints = tf.contrib.tpu.TPUEstimator(\n",
    "  use_tpu=True,\n",
    "  model_fn=model_fn,\n",
    "  config=get_run_config(OUTPUT_DIR),\n",
    "  train_batch_size=TRAIN_BATCH_SIZE,\n",
    "  eval_batch_size=EVAL_BATCH_SIZE,\n",
    "  predict_batch_size=PREDICT_BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yd61zFHgW2aN"
   },
   "source": [
    "Now, you can repeat the training, evaluation, and prediction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bZp2_qt4VvED",
    "outputId": "69373fc1-e826-46de-95fe-b4fea7d32c96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRPC/CoLA on BERT base model normally takes about 2-3 minutes. Please wait...\n",
      "***** Started training at 2019-07-16 20:55:47.538873 *****\n",
      "  Num examples = 5920\n",
      "  Batch size = 16\n",
      "***** Finished training at 2019-07-16 21:00:29.951544 *****\n"
     ]
    }
   ],
   "source": [
    "model_train(estimator_from_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "QIdXkglNVxM5",
    "outputId": "28753319-ce49-42d5-d60d-3edbfb4d70f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Started evaluation at 2019-07-16 21:00:56.832073 *****\n",
      "  Num examples = 1974\n",
      "  Batch size = 8\n",
      "***** Finished evaluation at 2019-07-16 21:01:44.610197 *****\n",
      "***** Eval results *****\n",
      "  eval_accuracy = 0.9324187\n",
      "  eval_loss = 0.38113514\n",
      "  global_step = 5180\n",
      "  loss = 0.18948396\n"
     ]
    }
   ],
   "source": [
    "model_eval(estimator_from_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "0yamCRHcV-nQ",
    "outputId": "4251bf8d-4e7e-4bd8-c83d-8500917db099"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e7036d8b5092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator_from_checkpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_predict' is not defined"
     ]
    }
   ],
   "source": [
    "model_predict(estimator_from_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4ft65Ss-boU"
   },
   "outputs": [],
   "source": [
    "def model_predict_final(estimator):\n",
    "  #Make predictions on a subset of eval examples\n",
    "  prediction_examples = processor.get_test_examples(TASK_DATA_DIR)#[:PREDICT_BATCH_SIZE]\n",
    "  input_features = run_classifier.convert_examples_to_features(prediction_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=True)\n",
    "  predictions = estimator.predict(predict_input_fn)\n",
    "  \n",
    "  return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KltzNmqf8Kii",
    "outputId": "35ed3825-8fc3-42cd-e8aa-55d827d6967b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4251\n"
     ]
    }
   ],
   "source": [
    "result = model_predict_final(estimator_from_checkpoints)\n",
    "output_predict_file = ('test_results.tsv')\n",
    "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
    "  num_written_lines = 0\n",
    "  tf.logging.info(\"***** Predict results *****\")\n",
    "  for prediction in result:\n",
    "    probabilities = prediction[\"probabilities\"]\n",
    "    output_line = \"\\t\".join(\n",
    "        str(class_probability)\n",
    "        for class_probability in probabilities) + \"\\n\"\n",
    "    writer.write(output_line)\n",
    "    num_written_lines += 1\n",
    "print(num_written_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dVBJ8S24x9QX",
    "outputId": "1ecabec3-7940-47a4-9d97-d533a3cc19f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4251\n"
     ]
    }
   ],
   "source": [
    "predictions = pd.read_csv('test_results.tsv', header=None, sep='\\t')\n",
    "\n",
    "df_results_csv = pd.DataFrame({'id':range(len(predictions)), 'category':le.inverse_transform(predictions.idxmax(axis=1))})\n",
    "df_result_matriz_conf = pd.DataFrame({'category':predictions.idxmax(axis=1)})\n",
    "\n",
    "# writing into .csv\n",
    "df_results_csv.to_csv('submission_valid.csv',index=None)\n",
    "df_results_csv.head()\n",
    "print(len(df_results_csv))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BERT_End_to_End_with_Cloud_TPU_FASAM.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
