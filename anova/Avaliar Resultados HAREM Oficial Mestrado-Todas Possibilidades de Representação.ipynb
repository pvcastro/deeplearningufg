{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import pandas\n",
    "import researchpy as rp\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_results = Path('/media/discoD/models/elmo/ner/results_20_epochs_ibm')\n",
    "#path_results = Path('/media/discoD/models/elmo/ner/results_1_epoch_harem_all_combinations')\n",
    "path_results = Path('/opt/models/elmo/ner/results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/models/elmo/ner/results/datalawyer_ELMo+Embeddings\n",
      "/opt/models/elmo/ner/results/datalawyer-ft_ELMo+CNN+Embeddings\n",
      "/opt/models/elmo/ner/results/datalawyer_ELMo+CNN+Embeddings\n",
      "/opt/models/elmo/ner/results/datalawyer_ELMo\n",
      "/opt/models/elmo/ner/results/datalawyer_ELMo+CNN\n"
     ]
    }
   ],
   "source": [
    "for folder in path_results.iterdir():\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics.json not found for datalawyer-ft_ELMo+CNN+Embeddings_fasttext_cbow_0\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "configs = dict()\n",
    "metrics = dict()\n",
    "for folder in path_results.iterdir():\n",
    "    results_model_folder = folder.iterdir()\n",
    "    for training_folder in results_model_folder:\n",
    "        #print('Reading files from %s' % training_folder.name)\n",
    "        has_metrics = False\n",
    "        for results_file in training_folder.iterdir():\n",
    "            if results_file.name.endswith('.json'):\n",
    "                #print('Parsing data from %s' % results_file.name)\n",
    "                if results_file.name.startswith('config'):\n",
    "                    configs[training_folder.name] = json.loads(results_file.read_bytes())\n",
    "                elif results_file.name.startswith('metrics.'):\n",
    "                    metrics[training_folder.name] = json.loads(results_file.read_bytes())\n",
    "                    has_metrics = True\n",
    "        if not has_metrics:\n",
    "            print('metrics.json not found for %s' % training_folder.name)\n",
    "            del configs[training_folder.name]\n",
    "print(len(metrics))\n",
    "print(len(configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seconds(time_str):\n",
    "    x = time.strptime(time_str,'%H:%M:%S')\n",
    "    return datetime.timedelta(hours=x.tm_hour,minutes=x.tm_min,seconds=x.tm_sec).total_seconds()\n",
    "def get_average_epoch_duration(metrics):\n",
    "    seconds = get_seconds(metrics['training_duration'])\n",
    "    training_epochs = metrics['training_epochs'] + 1\n",
    "    return seconds / training_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Training_ID',\n",
       " 'Model',\n",
       " 'Representation',\n",
       " 'Embedding',\n",
       " 'Embedding_Type',\n",
       " 'Training_Number',\n",
       " 'Execution_Number',\n",
       " 'Best_Epoch',\n",
       " 'Training_Epochs',\n",
       " 'Training_Duration',\n",
       " 'Total_Duration(s)',\n",
       " 'Average_Epoch_Duration(s)',\n",
       " 'Training_Accuracy',\n",
       " 'Training_Accuracy_Top-3',\n",
       " 'Training_Precision',\n",
       " 'Training_Recall',\n",
       " 'Training_F1-Measure',\n",
       " 'Training_Loss',\n",
       " 'Best_Validation_Accuracy',\n",
       " 'Best_Validation_Accuracy_Top-3',\n",
       " 'Best_Validation_Precision',\n",
       " 'Best_Validation_Recall',\n",
       " 'Best_Validation_F1-Measure',\n",
       " 'Best_Validation_Loss',\n",
       " 'Test_Accuracy',\n",
       " 'Test_Accuracy_Top-3',\n",
       " 'Test_Precision',\n",
       " 'Test_Recall',\n",
       " 'Test_F1_Measure',\n",
       " 'Test_Loss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_ID = 'Training_ID'\n",
    "SCENARIO = 'Scenario'\n",
    "MODEL = 'Model'\n",
    "REPRESENTATION = 'Representation'\n",
    "EMBEDDING = 'Embedding'\n",
    "EMBEDDING_TYPE = 'Embedding_Type'\n",
    "BATCH_SIZE = 'Batch_Size'\n",
    "ELMO_DROPOUT = 'ELMo_Dropout'\n",
    "TRAINING_NUMBER = 'Training_Number'\n",
    "EXECUTION_NUMBER = 'Execution_Number'\n",
    "BEST_EPOCH = 'Best_Epoch'\n",
    "TRAINING_EPOCHS = 'Training_Epochs'\n",
    "TRAINING_DURATION = 'Training_Duration'\n",
    "TOTAL_DURATION = 'Total_Duration(s)'\n",
    "AVERAGE_EPOCH_DURATION = 'Average_Epoch_Duration(s)'\n",
    "TRAINING_ACCURACY = 'Training_Accuracy'\n",
    "TRAINING_ACCURACY_TOP3 = 'Training_Accuracy_Top-3'\n",
    "TRAINING_PRECISION = 'Training_Precision'\n",
    "TRAINING_RECALL = 'Training_Recall'\n",
    "TRAINING_F1_MEASURE = 'Training_F1-Measure'\n",
    "TRAINING_LOSS = 'Training_Loss'\n",
    "BEST_VALIDATION_ACCURACY = 'Best_Validation_Accuracy'\n",
    "BEST_VALIDATION_ACCURACY_TOP3 = 'Best_Validation_Accuracy_Top-3'\n",
    "BEST_VALIDATION_PRECISION = 'Best_Validation_Precision'\n",
    "BEST_VALIDATION_RECALL = 'Best_Validation_Recall'\n",
    "BEST_VALIDATION_F1_MEASURE = 'Best_Validation_F1-Measure'\n",
    "BEST_VALIDATION_LOSS = 'Best_Validation_Loss'\n",
    "TEST_ACCURACY = 'Test_Accuracy'\n",
    "TEST_ACCURACY_TOP3 = 'Test_Accuracy_Top-3'\n",
    "TEST_PRECISION = 'Test_Precision'\n",
    "TEST_RECALL = 'Test_Recall'\n",
    "TEST_F1_MEASURE = 'Test_F1_Measure'\n",
    "TEST_LOSS = 'Test_Loss'\n",
    "columns = [TRAINING_ID, MODEL, REPRESENTATION, EMBEDDING, EMBEDDING_TYPE, TRAINING_NUMBER, EXECUTION_NUMBER, BEST_EPOCH, TRAINING_EPOCHS, TRAINING_DURATION, TOTAL_DURATION, AVERAGE_EPOCH_DURATION, TRAINING_ACCURACY, TRAINING_ACCURACY_TOP3, TRAINING_PRECISION, TRAINING_RECALL, TRAINING_F1_MEASURE, TRAINING_LOSS, BEST_VALIDATION_ACCURACY, BEST_VALIDATION_ACCURACY_TOP3, BEST_VALIDATION_PRECISION, BEST_VALIDATION_RECALL, BEST_VALIDATION_F1_MEASURE, BEST_VALIDATION_LOSS, TEST_ACCURACY, TEST_ACCURACY_TOP3, TEST_PRECISION, TEST_RECALL, TEST_F1_MEASURE, TEST_LOSS]\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data_from_id(training_id, config):\n",
    "    data = training_id.split('_')\n",
    "    print(data)\n",
    "    if len(data) == 4:\n",
    "        return {MODEL: data[0], REPRESENTATION: data[1], EMBEDDING: 'No', EMBEDDING_TYPE: 'No', TRAINING_NUMBER: data[2], EXECUTION_NUMBER: data[3]}\n",
    "    elif len(data) == 5:\n",
    "        #GloVe\n",
    "        return {MODEL: data[0], REPRESENTATION: data[1], EMBEDDING: data[2], EMBEDDING_TYPE: 'No', TRAINING_NUMBER: data[3], EXECUTION_NUMBER: data[4]}\n",
    "    elif len(data) == 6:\n",
    "        return {MODEL: data[0], REPRESENTATION: data[1], EMBEDDING: data[2], EMBEDDING_TYPE: data[3], TRAINING_NUMBER: data[4], EXECUTION_NUMBER: data[5]}\n",
    "    else:\n",
    "        print('Check id: %s' % training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['datalawyer', 'ELMo+Embeddings', 'fasttext', 'skip', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'fasttext', 'cbow', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'wang2vec', 'skip', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'word2vec', 'cbow', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'wang2vec', 'cbow', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'glove', '0']\n",
      "['datalawyer', 'ELMo+Embeddings', 'word2vec', 'skip', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'word2vec', 'skip', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'fasttext', 'skip', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'glove', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'wang2vec', 'cbow', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'wang2vec', 'skip', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'fasttext', 'cbow', '0']\n",
      "['datalawyer', 'ELMo+CNN+Embeddings', 'word2vec', 'cbow', '0']\n",
      "['datalawyer', 'ELMo', '0']\n",
      "Check id: datalawyer_ELMo_0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c2d2d9565fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_data_from_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAINING_ID\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mBEST_EPOCH\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraining_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAINING_EPOCHS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training_epochs'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraining_metrics\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "training_data = []\n",
    "for training_id, config in configs.items():\n",
    "    training_metrics = metrics[training_id]\n",
    "    data = get_training_data_from_id(training_id, config)\n",
    "    data[TRAINING_ID] = training_id\n",
    "    data[BEST_EPOCH] = training_metrics['best_epoch'] if training_metrics else None\n",
    "    data[TRAINING_EPOCHS] = training_metrics['training_epochs'] + 1 if training_metrics else None\n",
    "    data[TRAINING_DURATION] = training_metrics['training_duration'] if training_metrics else None\n",
    "    data[TOTAL_DURATION] = get_seconds(training_metrics['training_duration']) if training_metrics else None\n",
    "    data[AVERAGE_EPOCH_DURATION] = get_average_epoch_duration(training_metrics) if training_metrics else None\n",
    "    data[TRAINING_ACCURACY] = training_metrics['training_accuracy'] if training_metrics else None\n",
    "    data[TRAINING_ACCURACY_TOP3] = training_metrics['training_accuracy3'] if training_metrics else None\n",
    "    data[TRAINING_PRECISION] = training_metrics['training_precision-overall'] if training_metrics else None\n",
    "    data[TRAINING_RECALL] = training_metrics['training_recall-overall'] if training_metrics else None\n",
    "    data[TRAINING_F1_MEASURE] = training_metrics['training_f1-measure-overall'] if training_metrics else None\n",
    "    data[TRAINING_LOSS] = training_metrics['training_loss'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY] = training_metrics['best_validation_accuracy'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_ACCURACY_TOP3] = training_metrics['best_validation_accuracy3'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_PRECISION] = training_metrics['best_validation_precision-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_RECALL] = training_metrics['best_validation_recall-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_F1_MEASURE] = training_metrics['best_validation_f1-measure-overall'] if training_metrics else None\n",
    "    data[BEST_VALIDATION_LOSS] = training_metrics['best_validation_loss'] if training_metrics else None\n",
    "    data[TEST_ACCURACY] = training_metrics['test_accuracy'] if training_metrics else None\n",
    "    data[TEST_ACCURACY_TOP3] = training_metrics['test_accuracy3'] if training_metrics else None\n",
    "    data[TEST_PRECISION] = training_metrics['test_precision-overall'] if training_metrics else None\n",
    "    data[TEST_RECALL] = training_metrics['test_recall-overall'] if training_metrics else None\n",
    "    data[TEST_F1_MEASURE] = training_metrics['test_f1-measure-overall'] if training_metrics else None\n",
    "    data[TEST_LOSS] = training_metrics['test_loss'] if training_metrics else None\n",
    "    training_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "training_data_df = pd.DataFrame(training_data, columns=columns)\n",
    "training_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.to_csv('training_data_20_epochs_mestrado_datalawyer_all_reps.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(datetime.timedelta(seconds=training_data_df[TOTAL_DURATION].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_exported_columns = ['mean', 'min', 'max', 'std']\n",
    "\n",
    "def get_group_csv(group_name, group_columns, target_value, dataframe=training_data_df, exported_columns=default_exported_columns):\n",
    "    group = dataframe.groupby(group_columns).describe()[target_value].sort_values(by='mean', ascending=False)\n",
    "    for column in exported_columns:\n",
    "        group[column] = group[column] * 100\n",
    "    group.to_csv('grupo_' + group_name + '_20_epochs_mestrado_all_reps.csv', columns=exported_columns, float_format = '%.2f%%')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_group_csv(MODEL, MODEL, TEST_F1_MEASURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_group_csv(REPRESENTATION, REPRESENTATION, TEST_F1_MEASURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_group_csv(EMBEDDING_TYPE, EMBEDDING_TYPE, TEST_F1_MEASURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_group_csv(EMBEDDING, EMBEDDING, TEST_F1_MEASURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_group_csv('Model_Rep_Emb_Emb-Typ', [MODEL, REPRESENTATION, EMBEDDING, EMBEDDING_TYPE], TEST_F1_MEASURE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.groupby([MODEL, REPRESENTATION, EMBEDDING, EMBEDDING_TYPE]).describe()[TEST_F1_MEASURE].sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.groupby([EMBEDDING, EMBEDDING_TYPE]).describe()[TEST_F1_MEASURE].sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_skip_df = training_data_df[training_data_df[EMBEDDING_TYPE] != 'cbow']\n",
    "training_data_skip_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_skip_df.groupby([EMBEDDING]).describe()[TEST_F1_MEASURE].sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_cbow_df = training_data_df[training_data_df[EMBEDDING_TYPE] != 'skip']\n",
    "training_data_cbow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_cbow_df.groupby([EMBEDDING]).describe()[TEST_F1_MEASURE].sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[BEST_EPOCH].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[TOTAL_DURATION].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.groupby([TRAINING_NUMBER]).describe()[TEST_F1_MEASURE].sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(training_data_df[TEST_F1_MEASURE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.summary_cont(training_data_df.groupby(EMBEDDING))[TEST_F1_MEASURE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating effect size\n",
    "def anova_table(aov):\n",
    "    aov['mean_sq'] = aov[:]['sum_sq']/aov[:]['df']\n",
    "    \n",
    "    aov['eta_sq'] = aov[:-1]['sum_sq']/sum(aov['sum_sq'])\n",
    "    \n",
    "    aov['omega_sq'] = (aov[:-1]['sum_sq']-(aov[:-1]['df']*aov['mean_sq'][-1]))/(sum(aov['sum_sq'])+aov['mean_sq'][-1])\n",
    "    \n",
    "    cols = ['sum_sq', 'mean_sq', 'df', 'F', 'PR(>F)', 'eta_sq', 'omega_sq']\n",
    "    aov = aov[cols]\n",
    "    return aov\n",
    "\n",
    "def print_anova(parameter):\n",
    "    # Fits the model with the interaction term\n",
    "    # This will also automatically include the main effects for each factor\n",
    "    model = ols('Test_F1_Measure ~ C({0})'.format(parameter), training_data_df).fit()\n",
    "    # Seeing if the overall model is significant\n",
    "    print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .20f}\")\n",
    "    print(model.summary())\n",
    "    res = sm.stats.anova_lm(model, typ= 2)\n",
    "    print(res)\n",
    "    print(anova_table(res))\n",
    "    mc = statsmodels.stats.multicomp.MultiComparison(training_data_df[TEST_F1_MEASURE], training_data_df[parameter])\n",
    "    mc_results = mc.tukeyhsd()\n",
    "    print(mc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_anova(EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AllenNLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
